============================= test session starts =============================
platform win32 -- Python 3.11.5, pytest-7.3.1, pluggy-1.0.0
rootdir: C:\code\ghcwm\scikit-optimize
configfile: setup.cfg
plugins: anyio-3.7.0, hypothesis-6.82.0, asyncio-0.21.0, cov-4.1.0, xdist-3.3.1
asyncio: mode=Mode.STRICT
collected 445 items

test_acquisition.py .....FFFF.FF                                         [  2%]
test_benchmarks.py ..                                                    [  3%]
test_callbacks.py ...FF.                                                 [  4%]
test_common.py ....FFFF....FFFFFFFF....FFFFFFFF....FFFFFFFFF.FF.FF.FFF.F [ 17%]
F.FF.FFF.FF.FF.FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF..FFF.FFF.......... [ 33%]
F.FF.FF.FFF.FF.FF.FFFFFFFFFFFFFF                                         [ 40%]
test_deprecation.py .                                                    [ 40%]
test_dummy_opt.py ..                                                     [ 41%]
test_forest_opt.py ..FFFFF                                               [ 42%]
test_gp_opt.py ..FF.

================================== FAILURES ===================================
__________________________ test_acquisition_gradient __________________________

    @pytest.mark.fast_test
    def test_acquisition_gradient():
        rng = np.random.RandomState(0)
        X = rng.randn(20, 5)
        y = rng.randn(20)
        X_new = rng.randn(5)
        mat = Matern()
        wk = WhiteKernel()
        gpr = GaussianProcessRegressor(kernel=mat + wk)
        gpr.fit(X, y)
    
        for acq_func in ["LCB", "PI", "EI"]:
>           check_gradient_correctness(X_new, gpr, acq_func, np.max(y))

test_acquisition.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
test_acquisition.py:99: in check_gradient_correctness
    analytic_grad = gaussian_acquisition_1D(
..\acquisition.py:14: in gaussian_acquisition_1D
    return _gaussian_acquisition(np.expand_dims(X, axis=0),
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 0.37642553, -1.09940079,  0.29823817,  1.3263859 , -0.69456786]])
model = GaussianProcessRegressor(kernel=Matern(length_scale=1, nu=1.5) + WhiteKernel(noise_level=1))
y_opt = 1.9436211856492926, acq_func = 'PI', return_grad = True
acq_func_kwargs = {}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
>               acq_vals -= func_and_grad[0]
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:56: UnboundLocalError
_____________________ test_acquisition_gradient_cookbook ______________________

    @pytest.mark.fast_test
    def test_acquisition_gradient_cookbook():
        rng = np.random.RandomState(0)
        X = rng.randn(20, 5)
        y = rng.randn(20)
        X_new = rng.randn(5)
        gpr = cook_estimator("GP", Space(((-5.0, 5.0),)), random_state=0)
        gpr.fit(X, y)
    
        for acq_func in ["LCB", "PI", "EI"]:
>           check_gradient_correctness(X_new, gpr, acq_func, np.max(y))

test_acquisition.py:132: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
test_acquisition.py:99: in check_gradient_correctness
    analytic_grad = gaussian_acquisition_1D(
..\acquisition.py:14: in gaussian_acquisition_1D
    return _gaussian_acquisition(np.expand_dims(X, axis=0),
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 0.37642553, -1.09940079,  0.29823817,  1.3263859 , -0.69456786]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=1, nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=0)
y_opt = 1.9436211856492926, acq_func = 'PI', return_grad = True
acq_func_kwargs = {}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
>               acq_vals -= func_and_grad[0]
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:56: UnboundLocalError
______________________ test_acquisition_per_second[EIps] ______________________

acq_func = 'EIps'

    @pytest.mark.fast_test
    @pytest.mark.parametrize("acq_func", ["EIps", "PIps"])
    def test_acquisition_per_second(acq_func):
        X = np.reshape(np.linspace(4.0, 8.0, 10), (-1, 1))
        y = np.vstack((np.ones(10), np.ravel(np.log(X)))).T
        cgpr = ConstantGPRSurrogate(Space(((1.0, 9.0),)))
        cgpr.fit(X, y)
    
        X_pred = np.reshape(np.linspace(1.0, 11.0, 20), (-1, 1))
        indices = np.arange(6)
>       vals = _gaussian_acquisition(X_pred, cgpr, y_opt=1.0, acq_func=acq_func)

test_acquisition.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 1.        ],
       [ 1.52631579],
       [ 2.05263158],
       [ 2.57894737],
       [ 3.10526316],
       [...842105],
       [ 8.89473684],
       [ 9.42105263],
       [ 9.94736842],
       [10.47368421],
       [11.        ]])
model = <skopt.tests.test_acquisition.ConstSurrogate object at 0x000001BCF78195D0>
y_opt = 1.0, acq_func = 'EIps', return_grad = False, acq_func_kwargs = {}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
______________________ test_acquisition_per_second[PIps] ______________________

acq_func = 'PIps'

    @pytest.mark.fast_test
    @pytest.mark.parametrize("acq_func", ["EIps", "PIps"])
    def test_acquisition_per_second(acq_func):
        X = np.reshape(np.linspace(4.0, 8.0, 10), (-1, 1))
        y = np.vstack((np.ones(10), np.ravel(np.log(X)))).T
        cgpr = ConstantGPRSurrogate(Space(((1.0, 9.0),)))
        cgpr.fit(X, y)
    
        X_pred = np.reshape(np.linspace(1.0, 11.0, 20), (-1, 1))
        indices = np.arange(6)
>       vals = _gaussian_acquisition(X_pred, cgpr, y_opt=1.0, acq_func=acq_func)

test_acquisition.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 1.        ],
       [ 1.52631579],
       [ 2.05263158],
       [ 2.57894737],
       [ 3.10526316],
       [...842105],
       [ 8.89473684],
       [ 9.42105263],
       [ 9.94736842],
       [10.47368421],
       [11.        ]])
model = <skopt.tests.test_acquisition.ConstSurrogate object at 0x000001BCF76E6CD0>
y_opt = 1.0, acq_func = 'PIps', return_grad = False, acq_func_kwargs = {}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________ test_acquisition_per_second_gradient[EIps] __________________

acq_func = 'EIps'

    @pytest.mark.fast_test
    @pytest.mark.parametrize("acq_func", ["EIps", "PIps"])
    def test_acquisition_per_second_gradient(acq_func):
        rng = np.random.RandomState(0)
        X = rng.randn(20, 10)
        # Make the second component large, so that mean_grad and std_grad
        # do not become zero.
        y = np.vstack((X[:, 0], np.abs(X[:, 0])**3)).T
    
        for X_new in [rng.randn(10), rng.randn(10)]:
            gpr = cook_estimator("GP", Space(((-5.0, 5.0),)), random_state=0)
            mor = MultiOutputRegressor(gpr)
            mor.fit(X, y)
>           check_gradient_correctness(X_new, mor, acq_func, 1.5)

test_acquisition.py:176: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
test_acquisition.py:99: in check_gradient_correctness
    analytic_grad = gaussian_acquisition_1D(
..\acquisition.py:14: in gaussian_acquisition_1D
    return _gaussian_acquisition(np.expand_dims(X, axis=0),
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-0.36918184, -0.23937918,  1.0996596 ,  0.65526373,  0.64013153,
        -1.61695604, -0.02432612, -0.73803091,  0.2799246 , -0.09815039]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=1, nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=0)
y_opt = 1.5, acq_func = 'EIps', return_grad = True, acq_func_kwargs = {}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
>               acq_vals -= func_and_grad[0]
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:56: UnboundLocalError
_________________ test_acquisition_per_second_gradient[PIps] __________________

acq_func = 'PIps'

    @pytest.mark.fast_test
    @pytest.mark.parametrize("acq_func", ["EIps", "PIps"])
    def test_acquisition_per_second_gradient(acq_func):
        rng = np.random.RandomState(0)
        X = rng.randn(20, 10)
        # Make the second component large, so that mean_grad and std_grad
        # do not become zero.
        y = np.vstack((X[:, 0], np.abs(X[:, 0])**3)).T
    
        for X_new in [rng.randn(10), rng.randn(10)]:
            gpr = cook_estimator("GP", Space(((-5.0, 5.0),)), random_state=0)
            mor = MultiOutputRegressor(gpr)
            mor.fit(X, y)
>           check_gradient_correctness(X_new, mor, acq_func, 1.5)

test_acquisition.py:176: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
test_acquisition.py:99: in check_gradient_correctness
    analytic_grad = gaussian_acquisition_1D(
..\acquisition.py:14: in gaussian_acquisition_1D
    return _gaussian_acquisition(np.expand_dims(X, axis=0),
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-0.36918184, -0.23937918,  1.0996596 ,  0.65526373,  0.64013153,
        -1.61695604, -0.02432612, -0.73803091,  0.2799246 , -0.09815039]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=1, nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=0)
y_opt = 1.5, acq_func = 'PIps', return_grad = True, acq_func_kwargs = {}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
>               acq_vals -= func_and_grad[0]
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:56: UnboundLocalError
____________________________ test_deadline_stopper ____________________________

    @pytest.mark.fast_test
    def test_deadline_stopper():
        deadline = DeadlineStopper(0.0001)
        gp_minimize(bench3, [(-1.0, 1.0)], callback=deadline, n_calls=10, random_state=1)
        assert len(deadline.iter_time) == 1
        assert np.sum(deadline.iter_time) > deadline.total_time
    
        deadline = DeadlineStopper(60)
>       gp_minimize(bench3, [(-1.0, 1.0)], callback=deadline, n_calls=10, random_state=1)

test_callbacks.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.31327352],
       [0.52454816],
       [0.44345289],
       ...,
       [0.97933793],
       [0.67411393],
       [0.05899363]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=1, nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=1791095845)
y_opt = -0.8552720492399885, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_______________________ test_hollow_iterations_stopper ________________________

    @pytest.mark.fast_test
    def test_hollow_iterations_stopper():
        Result = namedtuple("Result", ["func_vals"])
    
        hollow = HollowIterationsStopper(3, 0)
        # will run at least n_iterations + 1 times
        assert not hollow(Result([10, 11, 12]))
        assert hollow(Result([10, 11, 12, 13]))
    
        # a tie is not enough
        assert hollow(Result([10, 11, 12, 10]))
    
        # every time we make a new min, we then have n_iterations rounds to beat it
        assert not hollow(Result([10, 9, 8, 7, 7, 7]))
        assert hollow(Result([10, 9, 8, 7, 7, 7, 7]))
    
        hollow = HollowIterationsStopper(3, 1.1)
        assert not hollow(Result([10, 11, 12, 8.89]))
        assert hollow(Result([10, 11, 12, 8.9]))
    
        # individual improvement below threshold contribute
        assert hollow(Result([10, 9.9, 9.8, 9.7]))
        assert not hollow(Result([10, 9.5, 9, 8.5, 8, 7.5]))
    
        hollow = HollowIterationsStopper(3, 0)
>       result = gp_minimize(
            bench3, [(-1.0, 1.0)], callback=hollow, n_calls=100, random_state=1
        )

test_callbacks.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.31327352],
       [0.52454816],
       [0.44345289],
       ...,
       [0.97933793],
       [0.67411393],
       [0.05899363]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=1, nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=1791095845)
y_opt = -0.8552720492399885, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
______________ test_minimizer_api[gp_minimize-call_single-True] _______________

verbose = True, call = <function call_single at 0x000001BCF6AFCB80>
minimizer = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.38791074, 0.65076216],
       [0.66974604, 0.97933793],
       [0.93553907, 0.67411393],
       ...,
       [0.33737522, 0.07951732],
       [0.56344925, 0.99317946],
       [0.33879252, 0.10041601]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=1791095845)
y_opt = 8.611668572056749, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
---------------------------- Captured stdout call -----------------------------
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.0005
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.0000
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 3 started. Evaluating function at random point.
______________ test_minimizer_api[gp_minimize-call_single-False] ______________

verbose = False, call = <function call_single at 0x000001BCF6AFCB80>
minimizer = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.38791074, 0.65076216],
       [0.66974604, 0.97933793],
       [0.93553907, 0.67411393],
       ...,
       [0.33737522, 0.07951732],
       [0.56344925, 0.99317946],
       [0.33879252, 0.10041601]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=1791095845)
y_opt = 8.611668572056749, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________ test_minimizer_api[gp_minimize-call1-True] __________________

verbose = True
call = [<function call_single at 0x000001BCF6AFCB80>, <function check_result_callable at 0x000001BCF6AFCAE0>, <skopt.callbacks.VerboseCallback object at 0x000001BCFBD6CB50>]
minimizer = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.38791074, 0.65076216],
       [0.66974604, 0.97933793],
       [0.93553907, 0.67411393],
       ...,
       [0.33737522, 0.07951732],
       [0.56344925, 0.99317946],
       [0.33879252, 0.10041601]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=1791095845)
y_opt = 8.611668572056749, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
---------------------------- Captured stdout call -----------------------------
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.0006
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.0000
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 3 started. Evaluating function at random point.
_________________ test_minimizer_api[gp_minimize-call1-False] _________________

verbose = False
call = [<function call_single at 0x000001BCF6AFCB80>, <function check_result_callable at 0x000001BCF6AFCAE0>, <skopt.callbacks.VerboseCallback object at 0x000001BCFBD6CB50>]
minimizer = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.38791074, 0.65076216],
       [0.66974604, 0.97933793],
       [0.93553907, 0.67411393],
       ...,
       [0.33737522, 0.07951732],
       [0.56344925, 0.99317946],
       [0.33879252, 0.10041601]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=1791095845)
y_opt = 8.611668572056749, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
---------------------------- Captured stdout call -----------------------------
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1788
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 4 started. Searching for the next optimal point.
Iteration No: 4 ended. Search finished for the next optimal point.
Time taken: 0.0000
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 5 started. Searching for the next optimal point.
_______________ test_minimizer_api[minimizer2-call_single-True] _______________

verbose = True, call = <function call_single at 0x000001BCF6AFCB80>
minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='ET', acq_func='PI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 0.81866112,  9.76143233],
       [ 5.04619055, 14.69006889],
       [ 9.03308606, 10.11170888],
       ...,
       [ 0.06062827,  1.19275978],
       [ 3.45173874, 14.89769183],
       [ 0.08188784,  1.50624012]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
---------------------------- Captured stdout call -----------------------------
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.0005
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.0000
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 3 started. Evaluating function at random point.
______________ test_minimizer_api[minimizer2-call_single-False] _______________

verbose = False, call = <function call_single at 0x000001BCF6AFCB80>
minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='ET', acq_func='PI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 0.81866112,  9.76143233],
       [ 5.04619055, 14.69006889],
       [ 9.03308606, 10.11170888],
       ...,
       [ 0.06062827,  1.19275978],
       [ 3.45173874, 14.89769183],
       [ 0.08188784,  1.50624012]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
__________________ test_minimizer_api[minimizer2-call1-True] __________________

verbose = True
call = [<function call_single at 0x000001BCF6AFCB80>, <function check_result_callable at 0x000001BCF6AFCAE0>, <skopt.callback...allbacks.VerboseCallback object at 0x000001BCFBD5C1D0>, <skopt.callbacks.VerboseCallback object at 0x000001BCF7C7B990>]
minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='ET', acq_func='PI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 0.81866112,  9.76143233],
       [ 5.04619055, 14.69006889],
       [ 9.03308606, 10.11170888],
       ...,
       [ 0.06062827,  1.19275978],
       [ 3.45173874, 14.89769183],
       [ 0.08188784,  1.50624012]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
---------------------------- Captured stdout call -----------------------------
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 19 ended. Search finished for the next optimal point.
Time taken: 1.5865
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 15 ended. Search finished for the next optimal point.
Time taken: 1.1186
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.0006
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 20 ended. Search finished for the next optimal point.
Time taken: 1.5866
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 16 ended. Search finished for the next optimal point.
Time taken: 1.1192
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.0005
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 3 started. Evaluating function at random point.
_________________ test_minimizer_api[minimizer2-call1-False] __________________

verbose = False
call = [<function call_single at 0x000001BCF6AFCB80>, <function check_result_callable at 0x000001BCF6AFCAE0>, <skopt.callback...allbacks.VerboseCallback object at 0x000001BCFBD5C1D0>, <skopt.callbacks.VerboseCallback object at 0x000001BCF7C7B990>]
minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='ET', acq_func='PI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 0.81866112,  9.76143233],
       [ 5.04619055, 14.69006889],
       [ 9.03308606, 10.11170888],
       ...,
       [ 0.06062827,  1.19275978],
       [ 3.45173874, 14.89769183],
       [ 0.08188784,  1.50624012]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
---------------------------- Captured stdout call -----------------------------
Iteration No: 21 ended. Search finished for the next optimal point.
Time taken: 1.7848
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 17 ended. Search finished for the next optimal point.
Time taken: 1.3169
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1977
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 4 started. Searching for the next optimal point.
Iteration No: 22 ended. Search finished for the next optimal point.
Time taken: 1.7854
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 18 ended. Search finished for the next optimal point.
Time taken: 1.3174
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 4 ended. Search finished for the next optimal point.
Time taken: 0.0006
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 5 started. Searching for the next optimal point.
_______________ test_minimizer_api[minimizer3-call_single-True] _______________

verbose = True, call = <function call_single at 0x000001BCF6AFCB80>
minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='ET', acq_func='EI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 0.81866112,  9.76143233],
       [ 5.04619055, 14.69006889],
       [ 9.03308606, 10.11170888],
       ...,
       [ 0.06062827,  1.19275978],
       [ 3.45173874, 14.89769183],
       [ 0.08188784,  1.50624012]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
---------------------------- Captured stdout call -----------------------------
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.0005
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.0000
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 3 started. Evaluating function at random point.
______________ test_minimizer_api[minimizer3-call_single-False] _______________

verbose = False, call = <function call_single at 0x000001BCF6AFCB80>
minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='ET', acq_func='EI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 0.81866112,  9.76143233],
       [ 5.04619055, 14.69006889],
       [ 9.03308606, 10.11170888],
       ...,
       [ 0.06062827,  1.19275978],
       [ 3.45173874, 14.89769183],
       [ 0.08188784,  1.50624012]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
__________________ test_minimizer_api[minimizer3-call1-True] __________________

verbose = True
call = [<function call_single at 0x000001BCF6AFCB80>, <function check_result_callable at 0x000001BCF6AFCAE0>, <skopt.callback...allbacks.VerboseCallback object at 0x000001BCF7C7B990>, <skopt.callbacks.VerboseCallback object at 0x000001BCFBEE3B90>]
minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='ET', acq_func='EI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 0.81866112,  9.76143233],
       [ 5.04619055, 14.69006889],
       [ 9.03308606, 10.11170888],
       ...,
       [ 0.06062827,  1.19275978],
       [ 3.45173874, 14.89769183],
       [ 0.08188784,  1.50624012]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
---------------------------- Captured stdout call -----------------------------
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 23 ended. Search finished for the next optimal point.
Time taken: 2.4397
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 19 ended. Search finished for the next optimal point.
Time taken: 1.9717
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 5 ended. Search finished for the next optimal point.
Time taken: 0.6548
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 6 started. Searching for the next optimal point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.0011
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 24 ended. Search finished for the next optimal point.
Time taken: 2.4402
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 20 ended. Search finished for the next optimal point.
Time taken: 1.9723
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 6 ended. Search finished for the next optimal point.
Time taken: 0.0006
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 7 started. Searching for the next optimal point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.0006
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 3 started. Evaluating function at random point.
_________________ test_minimizer_api[minimizer3-call1-False] __________________

verbose = False
call = [<function call_single at 0x000001BCF6AFCB80>, <function check_result_callable at 0x000001BCF6AFCAE0>, <skopt.callback...allbacks.VerboseCallback object at 0x000001BCF7C7B990>, <skopt.callbacks.VerboseCallback object at 0x000001BCFBEE3B90>]
minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='ET', acq_func='EI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 0.81866112,  9.76143233],
       [ 5.04619055, 14.69006889],
       [ 9.03308606, 10.11170888],
       ...,
       [ 0.06062827,  1.19275978],
       [ 3.45173874, 14.89769183],
       [ 0.08188784,  1.50624012]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
---------------------------- Captured stdout call -----------------------------
Iteration No: 25 ended. Search finished for the next optimal point.
Time taken: 2.6645
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 21 ended. Search finished for the next optimal point.
Time taken: 2.1965
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 7 ended. Search finished for the next optimal point.
Time taken: 0.2236
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.2236
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 4 started. Searching for the next optimal point.
Iteration No: 26 ended. Search finished for the next optimal point.
Time taken: 2.6650
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 22 ended. Search finished for the next optimal point.
Time taken: 2.1970
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 8 ended. Search finished for the next optimal point.
Time taken: 0.2242
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 4 ended. Search finished for the next optimal point.
Time taken: 0.0005
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 5 started. Searching for the next optimal point.
_______________ test_minimizer_api[minimizer5-call_single-True] _______________

verbose = True, call = <function call_single at 0x000001BCF6AFCB80>
minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='RF', acq_func='PI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 0.81866112,  9.76143233],
       [ 5.04619055, 14.69006889],
       [ 9.03308606, 10.11170888],
       ...,
       [ 0.06062827,  1.19275978],
       [ 3.45173874, 14.89769183],
       [ 0.08188784,  1.50624012]])
model = RandomForestRegressor(min_samples_leaf=3, n_estimators=100,
                      random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
---------------------------- Captured stdout call -----------------------------
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.0003
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.0000
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 3 started. Evaluating function at random point.
______________ test_minimizer_api[minimizer5-call_single-False] _______________

verbose = False, call = <function call_single at 0x000001BCF6AFCB80>
minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='RF', acq_func='PI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 0.81866112,  9.76143233],
       [ 5.04619055, 14.69006889],
       [ 9.03308606, 10.11170888],
       ...,
       [ 0.06062827,  1.19275978],
       [ 3.45173874, 14.89769183],
       [ 0.08188784,  1.50624012]])
model = RandomForestRegressor(min_samples_leaf=3, n_estimators=100,
                      random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
__________________ test_minimizer_api[minimizer5-call1-True] __________________

verbose = True
call = [<function call_single at 0x000001BCF6AFCB80>, <function check_result_callable at 0x000001BCF6AFCAE0>, <skopt.callback...cks.VerboseCallback object at 0x000001BCF7C7B990>, <skopt.callbacks.VerboseCallback object at 0x000001BCFBEE3B90>, ...]
minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='RF', acq_func='PI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 0.81866112,  9.76143233],
       [ 5.04619055, 14.69006889],
       [ 9.03308606, 10.11170888],
       ...,
       [ 0.06062827,  1.19275978],
       [ 3.45173874, 14.89769183],
       [ 0.08188784,  1.50624012]])
model = RandomForestRegressor(min_samples_leaf=3, n_estimators=100,
                      random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
---------------------------- Captured stdout call -----------------------------
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 41 ended. Search finished for the next optimal point.
Time taken: 6.1213
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 37 ended. Search finished for the next optimal point.
Time taken: 5.6533
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 23 ended. Search finished for the next optimal point.
Time taken: 3.6805
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 19 ended. Search finished for the next optimal point.
Time taken: 1.8560
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 15 ended. Search finished for the next optimal point.
Time taken: 1.2902
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.0011
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 42 ended. Search finished for the next optimal point.
Time taken: 6.1218
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 38 ended. Search finished for the next optimal point.
Time taken: 5.6539
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 24 ended. Search finished for the next optimal point.
Time taken: 3.6815
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 20 ended. Search finished for the next optimal point.
Time taken: 1.8571
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 16 ended. Search finished for the next optimal point.
Time taken: 1.2913
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.0005
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 3 started. Evaluating function at random point.
_________________ test_minimizer_api[minimizer5-call1-False] __________________

verbose = False
call = [<function call_single at 0x000001BCF6AFCB80>, <function check_result_callable at 0x000001BCF6AFCAE0>, <skopt.callback...cks.VerboseCallback object at 0x000001BCF7C7B990>, <skopt.callbacks.VerboseCallback object at 0x000001BCFBEE3B90>, ...]
minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='RF', acq_func='PI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 0.81866112,  9.76143233],
       [ 5.04619055, 14.69006889],
       [ 9.03308606, 10.11170888],
       ...,
       [ 0.06062827,  1.19275978],
       [ 3.45173874, 14.89769183],
       [ 0.08188784,  1.50624012]])
model = RandomForestRegressor(min_samples_leaf=3, n_estimators=100,
                      random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
---------------------------- Captured stdout call -----------------------------
Iteration No: 43 ended. Search finished for the next optimal point.
Time taken: 6.3479
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 39 ended. Search finished for the next optimal point.
Time taken: 5.8799
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 25 ended. Search finished for the next optimal point.
Time taken: 3.9071
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 21 ended. Search finished for the next optimal point.
Time taken: 2.0826
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 17 ended. Search finished for the next optimal point.
Time taken: 1.5168
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.2255
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 4 started. Searching for the next optimal point.
Iteration No: 44 ended. Search finished for the next optimal point.
Time taken: 6.3485
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 40 ended. Search finished for the next optimal point.
Time taken: 5.8805
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 26 ended. Search finished for the next optimal point.
Time taken: 3.9076
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 22 ended. Search finished for the next optimal point.
Time taken: 2.0831
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 18 ended. Search finished for the next optimal point.
Time taken: 1.5174
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 4 ended. Search finished for the next optimal point.
Time taken: 0.0006
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 5 started. Searching for the next optimal point.
_______________ test_minimizer_api[minimizer6-call_single-True] _______________

verbose = True, call = <function call_single at 0x000001BCF6AFCB80>
minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='RF', acq_func='EI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 0.81866112,  9.76143233],
       [ 5.04619055, 14.69006889],
       [ 9.03308606, 10.11170888],
       ...,
       [ 0.06062827,  1.19275978],
       [ 3.45173874, 14.89769183],
       [ 0.08188784,  1.50624012]])
model = RandomForestRegressor(min_samples_leaf=3, n_estimators=100,
                      random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
---------------------------- Captured stdout call -----------------------------
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.0000
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.0005
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 3 started. Evaluating function at random point.
______________ test_minimizer_api[minimizer6-call_single-False] _______________

verbose = False, call = <function call_single at 0x000001BCF6AFCB80>
minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='RF', acq_func='EI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 0.81866112,  9.76143233],
       [ 5.04619055, 14.69006889],
       [ 9.03308606, 10.11170888],
       ...,
       [ 0.06062827,  1.19275978],
       [ 3.45173874, 14.89769183],
       [ 0.08188784,  1.50624012]])
model = RandomForestRegressor(min_samples_leaf=3, n_estimators=100,
                      random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
__________________ test_minimizer_api[minimizer6-call1-True] __________________

verbose = True
call = [<function call_single at 0x000001BCF6AFCB80>, <function check_result_callable at 0x000001BCF6AFCAE0>, <skopt.callback...cks.VerboseCallback object at 0x000001BCF7C7B990>, <skopt.callbacks.VerboseCallback object at 0x000001BCFBEE3B90>, ...]
minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='RF', acq_func='EI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 0.81866112,  9.76143233],
       [ 5.04619055, 14.69006889],
       [ 9.03308606, 10.11170888],
       ...,
       [ 0.06062827,  1.19275978],
       [ 3.45173874, 14.89769183],
       [ 0.08188784,  1.50624012]])
model = RandomForestRegressor(min_samples_leaf=3, n_estimators=100,
                      random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
---------------------------- Captured stdout call -----------------------------
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 45 ended. Search finished for the next optimal point.
Time taken: 7.0257
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 41 ended. Search finished for the next optimal point.
Time taken: 6.5577
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 27 ended. Search finished for the next optimal point.
Time taken: 4.5849
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 23 ended. Search finished for the next optimal point.
Time taken: 2.7604
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 19 ended. Search finished for the next optimal point.
Time taken: 2.1946
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 5 ended. Search finished for the next optimal point.
Time taken: 0.6767
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 6 started. Searching for the next optimal point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.0006
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 46 ended. Search finished for the next optimal point.
Time taken: 7.0262
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 42 ended. Search finished for the next optimal point.
Time taken: 6.5583
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 28 ended. Search finished for the next optimal point.
Time taken: 4.5854
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 24 ended. Search finished for the next optimal point.
Time taken: 2.7609
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 20 ended. Search finished for the next optimal point.
Time taken: 2.1956
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 6 ended. Search finished for the next optimal point.
Time taken: 0.0011
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 7 started. Searching for the next optimal point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.0006
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 3 started. Evaluating function at random point.
_________________ test_minimizer_api[minimizer6-call1-False] __________________

verbose = False
call = [<function call_single at 0x000001BCF6AFCB80>, <function check_result_callable at 0x000001BCF6AFCAE0>, <skopt.callback...cks.VerboseCallback object at 0x000001BCF7C7B990>, <skopt.callbacks.VerboseCallback object at 0x000001BCFBEE3B90>, ...]
minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='RF', acq_func='EI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 0.81866112,  9.76143233],
       [ 5.04619055, 14.69006889],
       [ 9.03308606, 10.11170888],
       ...,
       [ 0.06062827,  1.19275978],
       [ 3.45173874, 14.89769183],
       [ 0.08188784,  1.50624012]])
model = RandomForestRegressor(min_samples_leaf=3, n_estimators=100,
                      random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
---------------------------- Captured stdout call -----------------------------
Iteration No: 47 ended. Search finished for the next optimal point.
Time taken: 7.2486
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 43 ended. Search finished for the next optimal point.
Time taken: 6.7806
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 29 ended. Search finished for the next optimal point.
Time taken: 4.8078
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 25 ended. Search finished for the next optimal point.
Time taken: 2.9833
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 21 ended. Search finished for the next optimal point.
Time taken: 2.4175
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 7 ended. Search finished for the next optimal point.
Time taken: 0.2223
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.2224
Function value obtained: 123.3261
Current minimum: 123.3261
Iteration No: 4 started. Searching for the next optimal point.
Iteration No: 48 ended. Search finished for the next optimal point.
Time taken: 7.2492
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 44 ended. Search finished for the next optimal point.
Time taken: 6.7812
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 30 ended. Search finished for the next optimal point.
Time taken: 4.8089
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 26 ended. Search finished for the next optimal point.
Time taken: 2.9844
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 22 ended. Search finished for the next optimal point.
Time taken: 2.4186
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 8 ended. Search finished for the next optimal point.
Time taken: 0.2229
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 4 ended. Search finished for the next optimal point.
Time taken: 0.0005
Function value obtained: 8.6117
Current minimum: 8.6117
Iteration No: 5 started. Searching for the next optimal point.
_______________ test_minimizer_api[minimizer8-call_single-True] _______________

verbose = True, call = <function call_single at 0x000001BCF6AFCB80>
minimizer = functools.partial(<function gbrt_minimize at 0x000001BCF6A1E200>, acq_func='PI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-2.20609683,  9.33066103],
       [ 0.18341091, 14.15906645],
       [ 0.95151211,  5.21491446],
       ...,
       [ 7.18297605, 14.21302446],
       [-1.44958512, 12.49185439],
       [-4.05764405, 14.98190438]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD9B040),
                                  random_state=RandomState(MT19937) at 0x1BCFBD9B040)
y_opt = 56.528740046921534, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
---------------------------- Captured stdout call -----------------------------
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.0006
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.0005
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 3 started. Evaluating function at random point.
______________ test_minimizer_api[minimizer8-call_single-False] _______________

verbose = False, call = <function call_single at 0x000001BCF6AFCB80>
minimizer = functools.partial(<function gbrt_minimize at 0x000001BCF6A1E200>, acq_func='PI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-2.20609683,  9.33066103],
       [ 0.18341091, 14.15906645],
       [ 0.95151211,  5.21491446],
       ...,
       [ 7.18297605, 14.21302446],
       [-1.44958512, 12.49185439],
       [-4.05764405, 14.98190438]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD98940),
                                  random_state=RandomState(MT19937) at 0x1BCFBD98940)
y_opt = 56.528740046921534, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
__________________ test_minimizer_api[minimizer8-call1-True] __________________

verbose = True
call = [<function call_single at 0x000001BCF6AFCB80>, <function check_result_callable at 0x000001BCF6AFCAE0>, <skopt.callback...cks.VerboseCallback object at 0x000001BCF7C7B990>, <skopt.callbacks.VerboseCallback object at 0x000001BCFBEE3B90>, ...]
minimizer = functools.partial(<function gbrt_minimize at 0x000001BCF6A1E200>, acq_func='PI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-2.20609683,  9.33066103],
       [ 0.18341091, 14.15906645],
       [ 0.95151211,  5.21491446],
       ...,
       [ 7.18297605, 14.21302446],
       [-1.44958512, 12.49185439],
       [-4.05764405, 14.98190438]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD9B540),
                                  random_state=RandomState(MT19937) at 0x1BCFBD9B540)
y_opt = 56.528740046921534, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
---------------------------- Captured stdout call -----------------------------
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 63 ended. Search finished for the next optimal point.
Time taken: 10.0363
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 59 ended. Search finished for the next optimal point.
Time taken: 9.5684
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 45 ended. Search finished for the next optimal point.
Time taken: 7.5957
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 41 ended. Search finished for the next optimal point.
Time taken: 5.7713
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 37 ended. Search finished for the next optimal point.
Time taken: 5.2055
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 23 ended. Search finished for the next optimal point.
Time taken: 3.0098
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 19 ended. Search finished for the next optimal point.
Time taken: 1.4766
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 15 ended. Search finished for the next optimal point.
Time taken: 1.0243
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.0008
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 64 ended. Search finished for the next optimal point.
Time taken: 10.0371
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 60 ended. Search finished for the next optimal point.
Time taken: 9.5692
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 46 ended. Search finished for the next optimal point.
Time taken: 7.5963
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 42 ended. Search finished for the next optimal point.
Time taken: 5.7718
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 38 ended. Search finished for the next optimal point.
Time taken: 5.2060
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 24 ended. Search finished for the next optimal point.
Time taken: 3.0103
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 20 ended. Search finished for the next optimal point.
Time taken: 1.4771
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 16 ended. Search finished for the next optimal point.
Time taken: 1.0254
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.0011
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 3 started. Evaluating function at random point.
_________________ test_minimizer_api[minimizer8-call1-False] __________________

verbose = False
call = [<function call_single at 0x000001BCF6AFCB80>, <function check_result_callable at 0x000001BCF6AFCAE0>, <skopt.callback...cks.VerboseCallback object at 0x000001BCF7C7B990>, <skopt.callbacks.VerboseCallback object at 0x000001BCFBEE3B90>, ...]
minimizer = functools.partial(<function gbrt_minimize at 0x000001BCF6A1E200>, acq_func='PI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-2.20609683,  9.33066103],
       [ 0.18341091, 14.15906645],
       [ 0.95151211,  5.21491446],
       ...,
       [ 7.18297605, 14.21302446],
       [-1.44958512, 12.49185439],
       [-4.05764405, 14.98190438]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD9B940),
                                  random_state=RandomState(MT19937) at 0x1BCFBD9B940)
y_opt = 56.528740046921534, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
---------------------------- Captured stdout call -----------------------------
Iteration No: 65 ended. Search finished for the next optimal point.
Time taken: 10.2267
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 61 ended. Search finished for the next optimal point.
Time taken: 9.7587
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 47 ended. Search finished for the next optimal point.
Time taken: 7.7859
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 43 ended. Search finished for the next optimal point.
Time taken: 5.9614
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 39 ended. Search finished for the next optimal point.
Time taken: 5.3956
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 25 ended. Search finished for the next optimal point.
Time taken: 3.2004
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 21 ended. Search finished for the next optimal point.
Time taken: 1.6672
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 17 ended. Search finished for the next optimal point.
Time taken: 1.2150
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1896
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 4 started. Searching for the next optimal point.
Iteration No: 66 ended. Search finished for the next optimal point.
Time taken: 10.2272
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 62 ended. Search finished for the next optimal point.
Time taken: 9.7598
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 48 ended. Search finished for the next optimal point.
Time taken: 7.7870
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 44 ended. Search finished for the next optimal point.
Time taken: 5.9625
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 40 ended. Search finished for the next optimal point.
Time taken: 5.3967
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 26 ended. Search finished for the next optimal point.
Time taken: 3.2010
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 22 ended. Search finished for the next optimal point.
Time taken: 1.6678
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 18 ended. Search finished for the next optimal point.
Time taken: 1.2155
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 4 ended. Search finished for the next optimal point.
Time taken: 0.0006
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 5 started. Searching for the next optimal point.
_______________ test_minimizer_api[minimizer9-call_single-True] _______________

verbose = True, call = <function call_single at 0x000001BCF6AFCB80>
minimizer = functools.partial(<function gbrt_minimize at 0x000001BCF6A1E200>, acq_func='EI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-2.20609683,  9.33066103],
       [ 0.18341091, 14.15906645],
       [ 0.95151211,  5.21491446],
       ...,
       [ 7.18297605, 14.21302446],
       [-1.44958512, 12.49185439],
       [-4.05764405, 14.98190438]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD9BA40),
                                  random_state=RandomState(MT19937) at 0x1BCFBD9BA40)
y_opt = 56.528740046921534, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
---------------------------- Captured stdout call -----------------------------
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.0005
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.0005
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 3 started. Evaluating function at random point.
______________ test_minimizer_api[minimizer9-call_single-False] _______________

verbose = False, call = <function call_single at 0x000001BCF6AFCB80>
minimizer = functools.partial(<function gbrt_minimize at 0x000001BCF6A1E200>, acq_func='EI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-2.20609683,  9.33066103],
       [ 0.18341091, 14.15906645],
       [ 0.95151211,  5.21491446],
       ...,
       [ 7.18297605, 14.21302446],
       [-1.44958512, 12.49185439],
       [-4.05764405, 14.98190438]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD98740),
                                  random_state=RandomState(MT19937) at 0x1BCFBD98740)
y_opt = 56.528740046921534, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
__________________ test_minimizer_api[minimizer9-call1-True] __________________

verbose = True
call = [<function call_single at 0x000001BCF6AFCB80>, <function check_result_callable at 0x000001BCF6AFCAE0>, <skopt.callback...cks.VerboseCallback object at 0x000001BCF7C7B990>, <skopt.callbacks.VerboseCallback object at 0x000001BCFBEE3B90>, ...]
minimizer = functools.partial(<function gbrt_minimize at 0x000001BCF6A1E200>, acq_func='EI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-2.20609683,  9.33066103],
       [ 0.18341091, 14.15906645],
       [ 0.95151211,  5.21491446],
       ...,
       [ 7.18297605, 14.21302446],
       [-1.44958512, 12.49185439],
       [-4.05764405, 14.98190438]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD9A340),
                                  random_state=RandomState(MT19937) at 0x1BCFBD9A340)
y_opt = 56.528740046921534, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
---------------------------- Captured stdout call -----------------------------
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 67 ended. Search finished for the next optimal point.
Time taken: 10.8137
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 63 ended. Search finished for the next optimal point.
Time taken: 10.3458
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 49 ended. Search finished for the next optimal point.
Time taken: 8.3729
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 45 ended. Search finished for the next optimal point.
Time taken: 6.5484
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 41 ended. Search finished for the next optimal point.
Time taken: 5.9826
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 27 ended. Search finished for the next optimal point.
Time taken: 3.7869
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 23 ended. Search finished for the next optimal point.
Time taken: 2.2537
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 19 ended. Search finished for the next optimal point.
Time taken: 1.8020
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 5 ended. Search finished for the next optimal point.
Time taken: 0.5859
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 6 started. Searching for the next optimal point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.0011
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 68 ended. Search finished for the next optimal point.
Time taken: 10.8142
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 64 ended. Search finished for the next optimal point.
Time taken: 10.3468
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 50 ended. Search finished for the next optimal point.
Time taken: 8.3740
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 46 ended. Search finished for the next optimal point.
Time taken: 6.5495
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 42 ended. Search finished for the next optimal point.
Time taken: 5.9837
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 28 ended. Search finished for the next optimal point.
Time taken: 3.7880
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 24 ended. Search finished for the next optimal point.
Time taken: 2.2548
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 20 ended. Search finished for the next optimal point.
Time taken: 1.8025
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 6 ended. Search finished for the next optimal point.
Time taken: 0.0006
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 7 started. Searching for the next optimal point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.0006
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 3 started. Evaluating function at random point.
_________________ test_minimizer_api[minimizer9-call1-False] __________________

verbose = False
call = [<function call_single at 0x000001BCF6AFCB80>, <function check_result_callable at 0x000001BCF6AFCAE0>, <skopt.callback...cks.VerboseCallback object at 0x000001BCF7C7B990>, <skopt.callbacks.VerboseCallback object at 0x000001BCFBEE3B90>, ...]
minimizer = functools.partial(<function gbrt_minimize at 0x000001BCF6A1E200>, acq_func='EI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("verbose", [True, False])
    @pytest.mark.parametrize("call",
                             [call_single, [call_single, check_result_callable]])
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api(verbose, call, minimizer):
        n_calls = 7
        n_initial_points = 3
        n_models = n_calls - n_initial_points + 1
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1,
                           verbose=verbose, callback=call)

test_common.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-2.20609683,  9.33066103],
       [ 0.18341091, 14.15906645],
       [ 0.95151211,  5.21491446],
       ...,
       [ 7.18297605, 14.21302446],
       [-1.44958512, 12.49185439],
       [-4.05764405, 14.98190438]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD9A640),
                                  random_state=RandomState(MT19937) at 0x1BCFBD9A640)
y_opt = 56.528740046921534, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
---------------------------- Captured stdout call -----------------------------
Iteration No: 69 ended. Search finished for the next optimal point.
Time taken: 10.9964
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 65 ended. Search finished for the next optimal point.
Time taken: 10.5285
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 51 ended. Search finished for the next optimal point.
Time taken: 8.5556
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 47 ended. Search finished for the next optimal point.
Time taken: 6.7311
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 43 ended. Search finished for the next optimal point.
Time taken: 6.1653
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 29 ended. Search finished for the next optimal point.
Time taken: 3.9696
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 25 ended. Search finished for the next optimal point.
Time taken: 2.4369
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 21 ended. Search finished for the next optimal point.
Time taken: 1.9847
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 7 ended. Search finished for the next optimal point.
Time taken: 0.1821
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1816
Function value obtained: 56.5287
Current minimum: 56.5287
Iteration No: 4 started. Searching for the next optimal point.
Iteration No: 70 ended. Search finished for the next optimal point.
Time taken: 10.9975
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 66 ended. Search finished for the next optimal point.
Time taken: 10.5295
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 52 ended. Search finished for the next optimal point.
Time taken: 8.5567
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 48 ended. Search finished for the next optimal point.
Time taken: 6.7322
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 44 ended. Search finished for the next optimal point.
Time taken: 6.1664
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 30 ended. Search finished for the next optimal point.
Time taken: 3.9707
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 26 ended. Search finished for the next optimal point.
Time taken: 2.4374
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 22 ended. Search finished for the next optimal point.
Time taken: 1.9852
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 8 ended. Search finished for the next optimal point.
Time taken: 0.1832
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 4 ended. Search finished for the next optimal point.
Time taken: 0.0010
Function value obtained: 172.6653
Current minimum: 56.5287
Iteration No: 5 started. Searching for the next optimal point.
_________________ test_minimizer_api_random_only[gp_minimize] _________________

minimizer = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.fast_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api_random_only(minimizer):
        # no models should be fit as we only evaluate at random points
        n_calls = 5
        n_initial_points = 5
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1)

test_common.py:138: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.31327352, 0.75555032],
       [0.52454816, 0.71669585],
       [0.44345289, 0.66429277],
       ...,
       [0.97933793, 0.59192319],
       [0.67411393, 0.94270371],
       [0.05899363, 0.83707045]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=1791095845)
y_opt = 8.611668572056749, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________ test_minimizer_api_random_only[minimizer2] __________________

minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='ET', acq_func='PI')

    @pytest.mark.fast_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api_random_only(minimizer):
        # no models should be fit as we only evaluate at random points
        n_calls = 5
        n_initial_points = 5
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1)

test_common.py:138: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-0.30089725, 11.33325473],
       [ 2.86822239, 10.7504377 ],
       [ 1.65179341,  9.9643916 ],
       ...,
       [ 9.69006889,  8.87884779],
       [ 5.11170888, 14.14055568],
       [-4.11509552, 12.55605674]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________ test_minimizer_api_random_only[minimizer3] __________________

minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='ET', acq_func='EI')

    @pytest.mark.fast_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api_random_only(minimizer):
        # no models should be fit as we only evaluate at random points
        n_calls = 5
        n_initial_points = 5
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1)

test_common.py:138: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-0.30089725, 11.33325473],
       [ 2.86822239, 10.7504377 ],
       [ 1.65179341,  9.9643916 ],
       ...,
       [ 9.69006889,  8.87884779],
       [ 5.11170888, 14.14055568],
       [-4.11509552, 12.55605674]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________ test_minimizer_api_random_only[minimizer5] __________________

minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='RF', acq_func='PI')

    @pytest.mark.fast_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api_random_only(minimizer):
        # no models should be fit as we only evaluate at random points
        n_calls = 5
        n_initial_points = 5
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1)

test_common.py:138: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-0.30089725, 11.33325473],
       [ 2.86822239, 10.7504377 ],
       [ 1.65179341,  9.9643916 ],
       ...,
       [ 9.69006889,  8.87884779],
       [ 5.11170888, 14.14055568],
       [-4.11509552, 12.55605674]])
model = RandomForestRegressor(min_samples_leaf=3, n_estimators=100,
                      random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________ test_minimizer_api_random_only[minimizer6] __________________

minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='RF', acq_func='EI')

    @pytest.mark.fast_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api_random_only(minimizer):
        # no models should be fit as we only evaluate at random points
        n_calls = 5
        n_initial_points = 5
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1)

test_common.py:138: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-0.30089725, 11.33325473],
       [ 2.86822239, 10.7504377 ],
       [ 1.65179341,  9.9643916 ],
       ...,
       [ 9.69006889,  8.87884779],
       [ 5.11170888, 14.14055568],
       [-4.11509552, 12.55605674]])
model = RandomForestRegressor(min_samples_leaf=3, n_estimators=100,
                      random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________ test_minimizer_api_random_only[minimizer8] __________________

minimizer = functools.partial(<function gbrt_minimize at 0x000001BCF6A1E200>, acq_func='PI')

    @pytest.mark.fast_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api_random_only(minimizer):
        # no models should be fit as we only evaluate at random points
        n_calls = 5
        n_initial_points = 5
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1)

test_common.py:138: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 1.28791772,  4.15840206],
       [ 5.27829251, 10.38110484],
       [-1.93321625,  2.75392432],
       ...,
       [ 9.15906645,  5.99968623],
       [ 0.21491446,  2.55065068],
       [ 1.50439397,  5.41473312]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD9A240),
                                  random_state=RandomState(MT19937) at 0x1BCFBD9A240)
y_opt = 27.68166689936483, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________ test_minimizer_api_random_only[minimizer9] __________________

minimizer = functools.partial(<function gbrt_minimize at 0x000001BCF6A1E200>, acq_func='EI')

    @pytest.mark.fast_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_api_random_only(minimizer):
        # no models should be fit as we only evaluate at random points
        n_calls = 5
        n_initial_points = 5
    
>       result = minimizer(branin, [(-5.0, 10.0), (0.0, 15.0)],
                           n_initial_points=n_initial_points,
                           n_calls=n_calls,
                           random_state=1)

test_common.py:138: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 1.28791772,  4.15840206],
       [ 5.27829251, 10.38110484],
       [-1.93321625,  2.75392432],
       ...,
       [ 9.15906645,  5.99968623],
       [ 0.21491446,  2.55065068],
       [ 1.50439397,  5.41473312]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD98640),
                                  random_state=RandomState(MT19937) at 0x1BCFBD98640)
y_opt = 27.68166689936483, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
____________________ test_fixed_random_states[gp_minimize] ____________________

minimizer = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_fixed_random_states(minimizer):
        # check that two runs produce exactly same results, if not there is a
        # random state somewhere that is not reproducible
        n_calls = 4
        n_initial_points = 2
    
        space = [(-5.0, 10.0), (0.0, 15.0)]
>       result1 = minimizer(branin, space, n_calls=n_calls,
                            n_initial_points=n_initial_points, random_state=1)

test_common.py:156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.23608898, 0.56344925],
       [0.39658073, 0.33879252],
       [0.38791074, 0.65076216],
       ...,
       [0.24662343, 0.34465128],
       [0.64833283, 0.6140608 ],
       [0.33737522, 0.07951732]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=1791095845)
y_opt = 8.611668572056749, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
____________________ test_fixed_random_states[minimizer2] _____________________

minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='ET', acq_func='PI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_fixed_random_states(minimizer):
        # check that two runs produce exactly same results, if not there is a
        # random state somewhere that is not reproducible
        n_calls = 4
        n_initial_points = 2
    
        space = [(-5.0, 10.0), (0.0, 15.0)]
>       result1 = minimizer(branin, space, n_calls=n_calls,
                            n_initial_points=n_initial_points, random_state=1)

test_common.py:156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-1.45866535,  8.45173874],
       [ 0.94871091,  5.08188784],
       [ 0.81866112,  9.76143233],
       ...,
       [-1.30064852,  5.16976921],
       [ 4.72499238,  9.21091206],
       [ 0.06062827,  1.19275978]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
____________________ test_fixed_random_states[minimizer3] _____________________

minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='ET', acq_func='EI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_fixed_random_states(minimizer):
        # check that two runs produce exactly same results, if not there is a
        # random state somewhere that is not reproducible
        n_calls = 4
        n_initial_points = 2
    
        space = [(-5.0, 10.0), (0.0, 15.0)]
>       result1 = minimizer(branin, space, n_calls=n_calls,
                            n_initial_points=n_initial_points, random_state=1)

test_common.py:156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-1.45866535,  8.45173874],
       [ 0.94871091,  5.08188784],
       [ 0.81866112,  9.76143233],
       ...,
       [-1.30064852,  5.16976921],
       [ 4.72499238,  9.21091206],
       [ 0.06062827,  1.19275978]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
____________________ test_fixed_random_states[minimizer5] _____________________

minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='RF', acq_func='PI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_fixed_random_states(minimizer):
        # check that two runs produce exactly same results, if not there is a
        # random state somewhere that is not reproducible
        n_calls = 4
        n_initial_points = 2
    
        space = [(-5.0, 10.0), (0.0, 15.0)]
>       result1 = minimizer(branin, space, n_calls=n_calls,
                            n_initial_points=n_initial_points, random_state=1)

test_common.py:156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-1.45866535,  8.45173874],
       [ 0.94871091,  5.08188784],
       [ 0.81866112,  9.76143233],
       ...,
       [-1.30064852,  5.16976921],
       [ 4.72499238,  9.21091206],
       [ 0.06062827,  1.19275978]])
model = RandomForestRegressor(min_samples_leaf=3, n_estimators=100,
                      random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
____________________ test_fixed_random_states[minimizer6] _____________________

minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='RF', acq_func='EI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_fixed_random_states(minimizer):
        # check that two runs produce exactly same results, if not there is a
        # random state somewhere that is not reproducible
        n_calls = 4
        n_initial_points = 2
    
        space = [(-5.0, 10.0), (0.0, 15.0)]
>       result1 = minimizer(branin, space, n_calls=n_calls,
                            n_initial_points=n_initial_points, random_state=1)

test_common.py:156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-1.45866535,  8.45173874],
       [ 0.94871091,  5.08188784],
       [ 0.81866112,  9.76143233],
       ...,
       [-1.30064852,  5.16976921],
       [ 4.72499238,  9.21091206],
       [ 0.06062827,  1.19275978]])
model = RandomForestRegressor(min_samples_leaf=3, n_estimators=100,
                      random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
____________________ test_fixed_random_states[minimizer8] _____________________

minimizer = functools.partial(<function gbrt_minimize at 0x000001BCF6A1E200>, acq_func='PI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_fixed_random_states(minimizer):
        # check that two runs produce exactly same results, if not there is a
        # random state somewhere that is not reproducible
        n_calls = 4
        n_initial_points = 2
    
        space = [(-5.0, 10.0), (0.0, 15.0)]
>       result1 = minimizer(branin, space, n_calls=n_calls,
                            n_initial_points=n_initial_points, random_state=1)

test_common.py:156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-2.79866164,  3.55041488],
       [-3.61492108,  0.94235595],
       [-2.20609683,  9.33066103],
       ...,
       [-0.37740842,  8.12381111],
       [ 6.03066824, 13.18330135],
       [ 7.18297605, 14.21302446]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD98340),
                                  random_state=RandomState(MT19937) at 0x1BCFBD98340)
y_opt = 56.528740046921534, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
____________________ test_fixed_random_states[minimizer9] _____________________

minimizer = functools.partial(<function gbrt_minimize at 0x000001BCF6A1E200>, acq_func='EI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_fixed_random_states(minimizer):
        # check that two runs produce exactly same results, if not there is a
        # random state somewhere that is not reproducible
        n_calls = 4
        n_initial_points = 2
    
        space = [(-5.0, 10.0), (0.0, 15.0)]
>       result1 = minimizer(branin, space, n_calls=n_calls,
                            n_initial_points=n_initial_points, random_state=1)

test_common.py:156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-2.79866164,  3.55041488],
       [-3.61492108,  0.94235595],
       [-2.20609683,  9.33066103],
       ...,
       [-0.37740842,  8.12381111],
       [ 6.03066824, 13.18330135],
       [ 7.18297605, 14.21302446]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD99C40),
                                  random_state=RandomState(MT19937) at 0x1BCFBD99C40)
y_opt = 56.528740046921534, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
___________________ test_minimizer_with_space[gp_minimize] ____________________

minimizer = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_with_space(minimizer):
        # check we can pass a Space instance as dimensions argument and get same
        # result
        n_calls = 4
        n_initial_points = 2
    
        space = Space([(-5.0, 10.0), (0.0, 15.0)])
>       space_result = minimizer(branin, space, n_calls=n_calls,
                                 n_initial_points=n_initial_points, random_state=1)

test_common.py:176: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.23608898, 0.56344925],
       [0.39658073, 0.33879252],
       [0.38791074, 0.65076216],
       ...,
       [0.24662343, 0.34465128],
       [0.64833283, 0.6140608 ],
       [0.33737522, 0.07951732]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=1791095845)
y_opt = 8.611668572056749, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
____________________ test_minimizer_with_space[minimizer2] ____________________

minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='ET', acq_func='PI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_with_space(minimizer):
        # check we can pass a Space instance as dimensions argument and get same
        # result
        n_calls = 4
        n_initial_points = 2
    
        space = Space([(-5.0, 10.0), (0.0, 15.0)])
>       space_result = minimizer(branin, space, n_calls=n_calls,
                                 n_initial_points=n_initial_points, random_state=1)

test_common.py:176: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-1.45866535,  8.45173874],
       [ 0.94871091,  5.08188784],
       [ 0.81866112,  9.76143233],
       ...,
       [-1.30064852,  5.16976921],
       [ 4.72499238,  9.21091206],
       [ 0.06062827,  1.19275978]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
____________________ test_minimizer_with_space[minimizer3] ____________________

minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='ET', acq_func='EI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_with_space(minimizer):
        # check we can pass a Space instance as dimensions argument and get same
        # result
        n_calls = 4
        n_initial_points = 2
    
        space = Space([(-5.0, 10.0), (0.0, 15.0)])
>       space_result = minimizer(branin, space, n_calls=n_calls,
                                 n_initial_points=n_initial_points, random_state=1)

test_common.py:176: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-1.45866535,  8.45173874],
       [ 0.94871091,  5.08188784],
       [ 0.81866112,  9.76143233],
       ...,
       [-1.30064852,  5.16976921],
       [ 4.72499238,  9.21091206],
       [ 0.06062827,  1.19275978]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
____________________ test_minimizer_with_space[minimizer5] ____________________

minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='RF', acq_func='PI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_with_space(minimizer):
        # check we can pass a Space instance as dimensions argument and get same
        # result
        n_calls = 4
        n_initial_points = 2
    
        space = Space([(-5.0, 10.0), (0.0, 15.0)])
>       space_result = minimizer(branin, space, n_calls=n_calls,
                                 n_initial_points=n_initial_points, random_state=1)

test_common.py:176: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-1.45866535,  8.45173874],
       [ 0.94871091,  5.08188784],
       [ 0.81866112,  9.76143233],
       ...,
       [-1.30064852,  5.16976921],
       [ 4.72499238,  9.21091206],
       [ 0.06062827,  1.19275978]])
model = RandomForestRegressor(min_samples_leaf=3, n_estimators=100,
                      random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
____________________ test_minimizer_with_space[minimizer6] ____________________

minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='RF', acq_func='EI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_with_space(minimizer):
        # check we can pass a Space instance as dimensions argument and get same
        # result
        n_calls = 4
        n_initial_points = 2
    
        space = Space([(-5.0, 10.0), (0.0, 15.0)])
>       space_result = minimizer(branin, space, n_calls=n_calls,
                                 n_initial_points=n_initial_points, random_state=1)

test_common.py:176: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-1.45866535,  8.45173874],
       [ 0.94871091,  5.08188784],
       [ 0.81866112,  9.76143233],
       ...,
       [-1.30064852,  5.16976921],
       [ 4.72499238,  9.21091206],
       [ 0.06062827,  1.19275978]])
model = RandomForestRegressor(min_samples_leaf=3, n_estimators=100,
                      random_state=1791095845)
y_opt = 8.611668572056729, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
____________________ test_minimizer_with_space[minimizer8] ____________________

minimizer = functools.partial(<function gbrt_minimize at 0x000001BCF6A1E200>, acq_func='PI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_with_space(minimizer):
        # check we can pass a Space instance as dimensions argument and get same
        # result
        n_calls = 4
        n_initial_points = 2
    
        space = Space([(-5.0, 10.0), (0.0, 15.0)])
>       space_result = minimizer(branin, space, n_calls=n_calls,
                                 n_initial_points=n_initial_points, random_state=1)

test_common.py:176: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-2.79866164,  3.55041488],
       [-3.61492108,  0.94235595],
       [-2.20609683,  9.33066103],
       ...,
       [-0.37740842,  8.12381111],
       [ 6.03066824, 13.18330135],
       [ 7.18297605, 14.21302446]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD9AB40),
                                  random_state=RandomState(MT19937) at 0x1BCFBD9AB40)
y_opt = 56.528740046921534, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
____________________ test_minimizer_with_space[minimizer9] ____________________

minimizer = functools.partial(<function gbrt_minimize at 0x000001BCF6A1E200>, acq_func='EI')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_minimizer_with_space(minimizer):
        # check we can pass a Space instance as dimensions argument and get same
        # result
        n_calls = 4
        n_initial_points = 2
    
        space = Space([(-5.0, 10.0), (0.0, 15.0)])
>       space_result = minimizer(branin, space, n_calls=n_calls,
                                 n_initial_points=n_initial_points, random_state=1)

test_common.py:176: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-2.79866164,  3.55041488],
       [-3.61492108,  0.94235595],
       [-2.20609683,  9.33066103],
       ...,
       [-0.37740842,  8.12381111],
       [ 6.03066824, 13.18330135],
       [ 7.18297605, 14.21302446]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD98740),
                                  random_state=RandomState(MT19937) at 0x1BCFBD98740)
y_opt = 56.528740046921534, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
__________________ test_init_vals_and_models[gp_minimize-0] ___________________

n_initial_points = 0
optimizer_func = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_vals_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points, y0 values
        # and random starts
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        y0 = list(map(branin, x0))
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, y0=y0, random_state=0,
                        n_calls=n_calls)

test_common.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:291: in base_minimize
    result = optimizer.tell(x0, y0)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.59284462, 0.38384988],
       [0.84426575, 0.95544143],
       [0.85794562, 0.59856546],
       ...,
       [0.11823814, 0.80467586],
       [0.4700401 , 0.9023541 ],
       [0.7884723 , 0.61056118]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=209652396)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
__________________ test_init_vals_and_models[gp_minimize-1] ___________________

n_initial_points = 1
optimizer_func = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_vals_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points, y0 values
        # and random starts
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        y0 = list(map(branin, x0))
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, y0=y0, random_state=0,
                        n_calls=n_calls)

test_common.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.85794562, 0.59856546],
       [0.84725174, 0.94201664],
       [0.6235637 , 0.5710934 ],
       ...,
       [0.7884723 , 0.61056118],
       [0.38384988, 0.85554495],
       [0.95544143, 0.48720747]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=209652396)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
__________________ test_init_vals_and_models[gp_minimize-2] ___________________

n_initial_points = 2
optimizer_func = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_vals_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points, y0 values
        # and random starts
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        y0 = list(map(branin, x0))
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, y0=y0, random_state=0,
                        n_calls=n_calls)

test_common.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.6235637 , 0.5710934 ],
       [0.38438171, 0.21022448],
       [0.29753461, 0.26139364],
       ...,
       [0.95544143, 0.48720747],
       [0.59856546, 0.57206492],
       [0.94201664, 0.32112269]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=209652396)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
__________________ test_init_vals_and_models[gp_minimize-3] ___________________

n_initial_points = 3
optimizer_func = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_vals_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points, y0 values
        # and random starts
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        y0 = list(map(branin, x0))
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, y0=y0, random_state=0,
                        n_calls=n_calls)

test_common.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.29753461, 0.26139364],
       [0.05671298, 0.58004736],
       [0.27265629, 0.82937833],
       ...,
       [0.94201664, 0.32112269],
       [0.5710934 , 0.21192153],
       [0.21022448, 0.9748539 ]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=209652396)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
__________________ test_init_vals_and_models[gp_minimize-4] ___________________

n_initial_points = 4
optimizer_func = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_vals_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points, y0 values
        # and random starts
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        y0 = list(map(branin, x0))
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, y0=y0, random_state=0,
                        n_calls=n_calls)

test_common.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.27265629, 0.82937833],
       [0.47766512, 0.19500384],
       [0.81216873, 0.54515769],
       ...,
       [0.21022448, 0.9748539 ],
       [0.26139364, 0.56653302],
       [0.58004736, 0.57732075]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=209652396)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________________ test_init_vals_and_models[forest_minimize-0] _________________

n_initial_points = 0
optimizer_func = <function forest_minimize at 0x000001BCF6A0FBA0>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_vals_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points, y0 values
        # and random starts
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        y0 = list(map(branin, x0))
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, y0=y0, random_state=0,
                        n_calls=n_calls)

test_common.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:291: in base_minimize
    result = optimizer.tell(x0, y0)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 3.89266927,  5.75774824],
       [ 7.66398623, 14.3316215 ],
       [ 7.86918426,  8.97848189],
       ...,
       [-3.22642784, 12.07013797],
       [ 2.05060156, 13.53531144],
       [ 6.82708451,  9.1584177 ]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=209652396)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________________ test_init_vals_and_models[forest_minimize-1] _________________

n_initial_points = 1
optimizer_func = <function forest_minimize at 0x000001BCF6A0FBA0>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_vals_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points, y0 values
        # and random starts
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        y0 = list(map(branin, x0))
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, y0=y0, random_state=0,
                        n_calls=n_calls)

test_common.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 7.86918426,  8.97848189],
       [ 7.70877608, 14.13024958],
       [ 4.35345545,  8.56640104],
       ...,
       [ 6.82708451,  9.1584177 ],
       [ 0.75774824, 12.83317432],
       [ 9.3316215 ,  7.30811208]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=209652396)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________________ test_init_vals_and_models[forest_minimize-2] _________________

n_initial_points = 2
optimizer_func = <function forest_minimize at 0x000001BCF6A0FBA0>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_vals_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points, y0 values
        # and random starts
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        y0 = list(map(branin, x0))
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, y0=y0, random_state=0,
                        n_calls=n_calls)

test_common.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 4.35345545,  8.56640104],
       [ 0.76572561,  3.15336713],
       [-0.5369809 ,  3.92090459],
       ...,
       [ 9.3316215 ,  7.30811208],
       [ 3.97848189,  8.58097386],
       [ 9.13024958,  4.81684036]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=209652396)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________________ test_init_vals_and_models[forest_minimize-3] _________________

n_initial_points = 3
optimizer_func = <function forest_minimize at 0x000001BCF6A0FBA0>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_vals_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points, y0 values
        # and random starts
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        y0 = list(map(branin, x0))
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, y0=y0, random_state=0,
                        n_calls=n_calls)

test_common.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-0.5369809 ,  3.92090459],
       [-4.14930534,  8.70071033],
       [-0.91015558, 12.44067492],
       ...,
       [ 9.13024958,  4.81684036],
       [ 3.56640104,  3.178823  ],
       [-1.84663287, 14.62280854]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=209652396)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________________ test_init_vals_and_models[forest_minimize-4] _________________

n_initial_points = 4
optimizer_func = <function forest_minimize at 0x000001BCF6A0FBA0>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_vals_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points, y0 values
        # and random starts
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        y0 = list(map(branin, x0))
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, y0=y0, random_state=0,
                        n_calls=n_calls)

test_common.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-0.91015558, 12.44067492],
       [ 2.16497676,  2.92505764],
       [ 7.18253093,  8.17736529],
       ...,
       [-1.84663287, 14.62280854],
       [-1.07909541,  8.4979953 ],
       [ 3.70071033,  8.65981128]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=209652396)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________ test_init_vals_and_models[gbrt_minimize-0] __________________

n_initial_points = 0
optimizer_func = <function gbrt_minimize at 0x000001BCF6A1E200>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_vals_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points, y0 values
        # and random starts
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        y0 = list(map(branin, x0))
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, y0=y0, random_state=0,
                        n_calls=n_calls)

test_common.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:291: in base_minimize
    result = optimizer.tell(x0, y0)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 3.23220256, 11.22401972],
       [ 5.7278405 ,  2.70304061],
       [ 4.04145064,  5.83534717],
       ...,
       [ 6.37644281,  6.69683641],
       [-4.64318859,  5.40189921],
       [ 7.2036262 ,  9.38829969]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD9B140),
                                  random_state=RandomState(MT19937) at 0x1BCFBD9B140)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________ test_init_vals_and_models[gbrt_minimize-1] __________________

n_initial_points = 1
optimizer_func = <function gbrt_minimize at 0x000001BCF6A1E200>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_vals_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points, y0 values
        # and random starts
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        y0 = list(map(branin, x0))
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, y0=y0, random_state=0,
                        n_calls=n_calls)

test_common.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 4.04145064,  5.83534717],
       [ 3.17324774,  0.56400272],
       [ 1.35482199,  0.17681609],
       ...,
       [ 7.2036262 ,  9.38829969],
       [ 6.22401972,  5.88259442],
       [-2.29695939,  0.61734879]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD98F40),
                                  random_state=RandomState(MT19937) at 0x1BCFBD98F40)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________ test_init_vals_and_models[gbrt_minimize-2] __________________

n_initial_points = 2
optimizer_func = <function gbrt_minimize at 0x000001BCF6A1E200>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_vals_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points, y0 values
        # and random starts
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        y0 = list(map(branin, x0))
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, y0=y0, random_state=0,
                        n_calls=n_calls)

test_common.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 1.35482199,  0.17681609],
       [ 4.6884117 , 14.94401807],
       [ 1.56380817,  7.32294987],
       ...,
       [-2.29695939,  0.61734879],
       [ 0.83534717, 13.84950853],
       [-4.43599728,  6.09352462]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD99240),
                                  random_state=RandomState(MT19937) at 0x1BCFBD99240)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________ test_init_vals_and_models[gbrt_minimize-3] __________________

n_initial_points = 3
optimizer_func = <function gbrt_minimize at 0x000001BCF6A1E200>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_vals_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points, y0 values
        # and random starts
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        y0 = list(map(branin, x0))
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, y0=y0, random_state=0,
                        n_calls=n_calls)

test_common.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 1.56380817,  7.32294987],
       [ 8.37659501,  5.58037146],
       [ 9.45494141,  2.94258142],
       ...,
       [-4.43599728,  6.09352462],
       [-4.82318391, 14.16423275],
       [ 9.94401807, 10.84086735]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD9A840),
                                  random_state=RandomState(MT19937) at 0x1BCFBD9A840)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________ test_init_vals_and_models[gbrt_minimize-4] __________________

n_initial_points = 4
optimizer_func = <function gbrt_minimize at 0x000001BCF6A1E200>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_vals_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points, y0 values
        # and random starts
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        y0 = list(map(branin, x0))
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, y0=y0, random_state=0,
                        n_calls=n_calls)

test_common.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 9.45494141,  2.94258142],
       [ 0.75162278, 12.10788368],
       [ 6.87587557, 10.58629079],
       ...,
       [ 9.94401807, 10.84086735],
       [ 2.32294987, 13.77479928],
       [ 0.58037146, 12.34901308]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD9A640),
                                  random_state=RandomState(MT19937) at 0x1BCFBD9A640)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________ test_init_points_and_models[gp_minimize-0] __________________

n_initial_points = 0
optimizer_func = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_points_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points and random
        # starts (no y0 in this case)
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, random_state=0,
                        n_calls=n_calls)

test_common.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:291: in base_minimize
    result = optimizer.tell(x0, y0)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.59284462, 0.38384988],
       [0.84426575, 0.95544143],
       [0.85794562, 0.59856546],
       ...,
       [0.11823814, 0.80467586],
       [0.4700401 , 0.9023541 ],
       [0.7884723 , 0.61056118]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=209652396)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________ test_init_points_and_models[gp_minimize-1] __________________

n_initial_points = 1
optimizer_func = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_points_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points and random
        # starts (no y0 in this case)
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, random_state=0,
                        n_calls=n_calls)

test_common.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.85794562, 0.59856546],
       [0.84725174, 0.94201664],
       [0.6235637 , 0.5710934 ],
       ...,
       [0.7884723 , 0.61056118],
       [0.38384988, 0.85554495],
       [0.95544143, 0.48720747]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=209652396)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________ test_init_points_and_models[gp_minimize-2] __________________

n_initial_points = 2
optimizer_func = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_points_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points and random
        # starts (no y0 in this case)
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, random_state=0,
                        n_calls=n_calls)

test_common.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.6235637 , 0.5710934 ],
       [0.38438171, 0.21022448],
       [0.29753461, 0.26139364],
       ...,
       [0.95544143, 0.48720747],
       [0.59856546, 0.57206492],
       [0.94201664, 0.32112269]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=209652396)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________ test_init_points_and_models[gp_minimize-3] __________________

n_initial_points = 3
optimizer_func = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_points_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points and random
        # starts (no y0 in this case)
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, random_state=0,
                        n_calls=n_calls)

test_common.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.29753461, 0.26139364],
       [0.05671298, 0.58004736],
       [0.27265629, 0.82937833],
       ...,
       [0.94201664, 0.32112269],
       [0.5710934 , 0.21192153],
       [0.21022448, 0.9748539 ]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=209652396)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________ test_init_points_and_models[gp_minimize-4] __________________

n_initial_points = 4
optimizer_func = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_points_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points and random
        # starts (no y0 in this case)
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, random_state=0,
                        n_calls=n_calls)

test_common.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.27265629, 0.82937833],
       [0.47766512, 0.19500384],
       [0.81216873, 0.54515769],
       ...,
       [0.21022448, 0.9748539 ],
       [0.26139364, 0.56653302],
       [0.58004736, 0.57732075]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=209652396)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_______________ test_init_points_and_models[forest_minimize-0] ________________

n_initial_points = 0
optimizer_func = <function forest_minimize at 0x000001BCF6A0FBA0>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_points_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points and random
        # starts (no y0 in this case)
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, random_state=0,
                        n_calls=n_calls)

test_common.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:291: in base_minimize
    result = optimizer.tell(x0, y0)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 3.89266927,  5.75774824],
       [ 7.66398623, 14.3316215 ],
       [ 7.86918426,  8.97848189],
       ...,
       [-3.22642784, 12.07013797],
       [ 2.05060156, 13.53531144],
       [ 6.82708451,  9.1584177 ]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=209652396)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_______________ test_init_points_and_models[forest_minimize-1] ________________

n_initial_points = 1
optimizer_func = <function forest_minimize at 0x000001BCF6A0FBA0>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_points_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points and random
        # starts (no y0 in this case)
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, random_state=0,
                        n_calls=n_calls)

test_common.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 7.86918426,  8.97848189],
       [ 7.70877608, 14.13024958],
       [ 4.35345545,  8.56640104],
       ...,
       [ 6.82708451,  9.1584177 ],
       [ 0.75774824, 12.83317432],
       [ 9.3316215 ,  7.30811208]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=209652396)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_______________ test_init_points_and_models[forest_minimize-2] ________________

n_initial_points = 2
optimizer_func = <function forest_minimize at 0x000001BCF6A0FBA0>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_points_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points and random
        # starts (no y0 in this case)
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, random_state=0,
                        n_calls=n_calls)

test_common.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 4.35345545,  8.56640104],
       [ 0.76572561,  3.15336713],
       [-0.5369809 ,  3.92090459],
       ...,
       [ 9.3316215 ,  7.30811208],
       [ 3.97848189,  8.58097386],
       [ 9.13024958,  4.81684036]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=209652396)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_______________ test_init_points_and_models[forest_minimize-3] ________________

n_initial_points = 3
optimizer_func = <function forest_minimize at 0x000001BCF6A0FBA0>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_points_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points and random
        # starts (no y0 in this case)
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, random_state=0,
                        n_calls=n_calls)

test_common.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-0.5369809 ,  3.92090459],
       [-4.14930534,  8.70071033],
       [-0.91015558, 12.44067492],
       ...,
       [ 9.13024958,  4.81684036],
       [ 3.56640104,  3.178823  ],
       [-1.84663287, 14.62280854]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=209652396)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_______________ test_init_points_and_models[forest_minimize-4] ________________

n_initial_points = 4
optimizer_func = <function forest_minimize at 0x000001BCF6A0FBA0>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_points_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points and random
        # starts (no y0 in this case)
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, random_state=0,
                        n_calls=n_calls)

test_common.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-0.91015558, 12.44067492],
       [ 2.16497676,  2.92505764],
       [ 7.18253093,  8.17736529],
       ...,
       [-1.84663287, 14.62280854],
       [-1.07909541,  8.4979953 ],
       [ 3.70071033,  8.65981128]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=209652396)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________________ test_init_points_and_models[gbrt_minimize-0] _________________

n_initial_points = 0
optimizer_func = <function gbrt_minimize at 0x000001BCF6A1E200>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_points_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points and random
        # starts (no y0 in this case)
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, random_state=0,
                        n_calls=n_calls)

test_common.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:291: in base_minimize
    result = optimizer.tell(x0, y0)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 3.23220256, 11.22401972],
       [ 5.7278405 ,  2.70304061],
       [ 4.04145064,  5.83534717],
       ...,
       [ 6.37644281,  6.69683641],
       [-4.64318859,  5.40189921],
       [ 7.2036262 ,  9.38829969]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD9A540),
                                  random_state=RandomState(MT19937) at 0x1BCFBD9A540)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________________ test_init_points_and_models[gbrt_minimize-1] _________________

n_initial_points = 1
optimizer_func = <function gbrt_minimize at 0x000001BCF6A1E200>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_points_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points and random
        # starts (no y0 in this case)
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, random_state=0,
                        n_calls=n_calls)

test_common.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 4.04145064,  5.83534717],
       [ 3.17324774,  0.56400272],
       [ 1.35482199,  0.17681609],
       ...,
       [ 7.2036262 ,  9.38829969],
       [ 6.22401972,  5.88259442],
       [-2.29695939,  0.61734879]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD9B340),
                                  random_state=RandomState(MT19937) at 0x1BCFBD9B340)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________________ test_init_points_and_models[gbrt_minimize-2] _________________

n_initial_points = 2
optimizer_func = <function gbrt_minimize at 0x000001BCF6A1E200>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_points_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points and random
        # starts (no y0 in this case)
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, random_state=0,
                        n_calls=n_calls)

test_common.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 1.35482199,  0.17681609],
       [ 4.6884117 , 14.94401807],
       [ 1.56380817,  7.32294987],
       ...,
       [-2.29695939,  0.61734879],
       [ 0.83534717, 13.84950853],
       [-4.43599728,  6.09352462]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD99240),
                                  random_state=RandomState(MT19937) at 0x1BCFBD99240)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________________ test_init_points_and_models[gbrt_minimize-3] _________________

n_initial_points = 3
optimizer_func = <function gbrt_minimize at 0x000001BCF6A1E200>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_points_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points and random
        # starts (no y0 in this case)
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, random_state=0,
                        n_calls=n_calls)

test_common.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 1.56380817,  7.32294987],
       [ 8.37659501,  5.58037146],
       [ 9.45494141,  2.94258142],
       ...,
       [-4.43599728,  6.09352462],
       [-4.82318391, 14.16423275],
       [ 9.94401807, 10.84086735]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCF7BFE840),
                                  random_state=RandomState(MT19937) at 0x1BCF7BFE840)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________________ test_init_points_and_models[gbrt_minimize-4] _________________

n_initial_points = 4
optimizer_func = <function gbrt_minimize at 0x000001BCF6A1E200>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [0, 1, 2, 3, 4])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_points_and_models(n_initial_points, optimizer_func):
        # test how many models are fitted when using initial points and random
        # starts (no y0 in this case)
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        n_calls = 7
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       res = optimizer(branin, space, x0=x0, random_state=0,
                        n_calls=n_calls)

test_common.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 9.45494141,  2.94258142],
       [ 0.75162278, 12.10788368],
       [ 6.87587557, 10.58629079],
       ...,
       [ 9.94401807, 10.84086735],
       [ 2.32294987, 13.77479928],
       [ 0.58037146, 12.34901308]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD9A240),
                                  random_state=RandomState(MT19937) at 0x1BCFBD9A240)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________________________ test_init_vals[gp_minimize-2] ________________________

n_initial_points = 2
optimizer_func = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [2, 5])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_vals(n_initial_points, optimizer_func):
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        n_calls = len(x0) + n_initial_points + 1
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       check_init_vals(optimizer, branin, space, x0, n_calls)

test_common.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
test_common.py:277: in check_init_vals
    res = optimizer(
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.6235637 , 0.5710934 ],
       [0.38438171, 0.21022448],
       [0.29753461, 0.26139364],
       ...,
       [0.95544143, 0.48720747],
       [0.59856546, 0.57206492],
       [0.94201664, 0.32112269]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=209652396)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________________________ test_init_vals[gp_minimize-5] ________________________

n_initial_points = 5
optimizer_func = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [2, 5])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_vals(n_initial_points, optimizer_func):
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        n_calls = len(x0) + n_initial_points + 1
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       check_init_vals(optimizer, branin, space, x0, n_calls)

test_common.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
test_common.py:277: in check_init_vals
    res = optimizer(
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.81216873, 0.54515769],
       [0.47997717, 0.35043353],
       [0.3927848 , 0.82845937],
       ...,
       [0.58004736, 0.57732075],
       [0.82937833, 0.57403375],
       [0.19500384, 0.91008712]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=209652396)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
______________________ test_init_vals[forest_minimize-2] ______________________

n_initial_points = 2
optimizer_func = <function forest_minimize at 0x000001BCF6A0FBA0>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [2, 5])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_vals(n_initial_points, optimizer_func):
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        n_calls = len(x0) + n_initial_points + 1
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       check_init_vals(optimizer, branin, space, x0, n_calls)

test_common.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
test_common.py:277: in check_init_vals
    res = optimizer(
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 4.35345545,  8.56640104],
       [ 0.76572561,  3.15336713],
       [-0.5369809 ,  3.92090459],
       ...,
       [ 9.3316215 ,  7.30811208],
       [ 3.97848189,  8.58097386],
       [ 9.13024958,  4.81684036]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=209652396)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
______________________ test_init_vals[forest_minimize-5] ______________________

n_initial_points = 5
optimizer_func = <function forest_minimize at 0x000001BCF6A0FBA0>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [2, 5])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_vals(n_initial_points, optimizer_func):
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        n_calls = len(x0) + n_initial_points + 1
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       check_init_vals(optimizer, branin, space, x0, n_calls)

test_common.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
test_common.py:277: in check_init_vals
    res = optimizer(
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 7.18253093,  8.17736529],
       [ 2.19965759,  5.25650301],
       [ 0.89177194, 12.42689052],
       ...,
       [ 3.70071033,  8.65981128],
       [ 7.44067492,  8.61050618],
       [-2.07494236, 13.65130683]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=209652396)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_______________________ test_init_vals[gbrt_minimize-2] _______________________

n_initial_points = 2
optimizer_func = <function gbrt_minimize at 0x000001BCF6A1E200>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [2, 5])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_vals(n_initial_points, optimizer_func):
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        n_calls = len(x0) + n_initial_points + 1
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       check_init_vals(optimizer, branin, space, x0, n_calls)

test_common.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
test_common.py:277: in check_init_vals
    res = optimizer(
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 1.35482199,  0.17681609],
       [ 4.6884117 , 14.94401807],
       [ 1.56380817,  7.32294987],
       ...,
       [-2.29695939,  0.61734879],
       [ 0.83534717, 13.84950853],
       [-4.43599728,  6.09352462]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD98E40),
                                  random_state=RandomState(MT19937) at 0x1BCFBD98E40)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_______________________ test_init_vals[gbrt_minimize-5] _______________________

n_initial_points = 5
optimizer_func = <function gbrt_minimize at 0x000001BCF6A1E200>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("n_initial_points", [2, 5])
    @pytest.mark.parametrize("optimizer_func",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_init_vals(n_initial_points, optimizer_func):
        space = [(-5.0, 10.0), (0.0, 15.0)]
        x0 = [[1, 2], [3, 4], [5, 6]]
        n_calls = len(x0) + n_initial_points + 1
    
        optimizer = partial(optimizer_func, n_initial_points=n_initial_points)
>       check_init_vals(optimizer, branin, space, x0, n_calls)

test_common.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
test_common.py:277: in check_init_vals
    res = optimizer(
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 6.87587557, 10.58629079],
       [ 2.9334238 ,  0.02334297],
       [ 3.52066842, 11.5684001 ],
       ...,
       [ 0.58037146, 12.34901308],
       [-2.05741858,  9.70345053],
       [ 7.10788368,  1.0190853 ]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD98940),
                                  random_state=RandomState(MT19937) at 0x1BCFBD98940)
y_opt = 3.092484911317573, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
___________________ test_categorical_init_vals[optimizer1] ____________________

optimizer = functools.partial(<function gp_minimize at 0x000001BCF6A1E160>, n_initial_points=3)

    @pytest.mark.slow_test
    @pytest.mark.parametrize("optimizer", [
            dummy_minimize,
            partial(gp_minimize, n_initial_points=3),
            partial(forest_minimize, n_initial_points=3),
            partial(gbrt_minimize, n_initial_points=3)])
    def test_categorical_init_vals(optimizer):
        space = [("-2", "-1", "0", "1", "2")]
        x0 = [["0"], ["1"], ["2"]]
        n_calls = 6
>       check_init_vals(optimizer, bench4, space, x0, n_calls)

test_common.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
test_common.py:277: in check_init_vals
    res = optimizer(
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.75],
       [0.5 ],
       [0.5 ],
       ...,
       [0.5 ],
       [1.  ],
       [0.5 ]])
model = GaussianProcessRegressor(kernel=1**2 * HammingKernel(0) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=209652396)
y_opt = 0.0, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
___________________ test_categorical_init_vals[optimizer2] ____________________

optimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, n_initial_points=3)

    @pytest.mark.slow_test
    @pytest.mark.parametrize("optimizer", [
            dummy_minimize,
            partial(gp_minimize, n_initial_points=3),
            partial(forest_minimize, n_initial_points=3),
            partial(gbrt_minimize, n_initial_points=3)])
    def test_categorical_init_vals(optimizer):
        space = [("-2", "-1", "0", "1", "2")]
        x0 = [["0"], ["1"], ["2"]]
        n_calls = 6
>       check_init_vals(optimizer, bench4, space, x0, n_calls)

test_common.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
test_common.py:277: in check_init_vals
    res = optimizer(
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0, 0, 0, 0, 1],
       [0, 0, 0, 1, 0],
       [0, 1, 0, 0, 0],
       ...,
       [0, 1, 0, 0, 0],
       [0, 0, 0, 0, 1],
       [0, 0, 1, 0, 0]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=209652396)
y_opt = 0.0, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
___________________ test_categorical_init_vals[optimizer3] ____________________

optimizer = functools.partial(<function gbrt_minimize at 0x000001BCF6A1E200>, n_initial_points=3)

    @pytest.mark.slow_test
    @pytest.mark.parametrize("optimizer", [
            dummy_minimize,
            partial(gp_minimize, n_initial_points=3),
            partial(forest_minimize, n_initial_points=3),
            partial(gbrt_minimize, n_initial_points=3)])
    def test_categorical_init_vals(optimizer):
        space = [("-2", "-1", "0", "1", "2")]
        x0 = [["0"], ["1"], ["2"]]
        n_calls = 6
>       check_init_vals(optimizer, bench4, space, x0, n_calls)

test_common.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
test_common.py:277: in check_init_vals
    res = optimizer(
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0, 0, 1, 0, 0],
       [0, 0, 1, 0, 0],
       [0, 0, 0, 1, 0],
       ...,
       [0, 0, 0, 1, 0],
       [1, 0, 0, 0, 0],
       [0, 1, 0, 0, 0]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD9A240),
                                  random_state=RandomState(MT19937) at 0x1BCFBD9A240)
y_opt = 0.0, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________________________ test_mixed_spaces[optimizer1] ________________________

optimizer = functools.partial(<function gp_minimize at 0x000001BCF6A1E160>, n_initial_points=2)

    @pytest.mark.slow_test
    @pytest.mark.parametrize("optimizer", [
            dummy_minimize,
            partial(gp_minimize, n_initial_points=2),
            partial(forest_minimize, n_initial_points=2),
            partial(gbrt_minimize, n_initial_points=2)])
    def test_mixed_spaces(optimizer):
        space = [("-2", "-1", "0", "1", "2"), (-2.0, 2.0)]
        x0 = [["0", 2.0], ["1", 1.0], ["2", 1.0]]
        n_calls = 5
>       check_init_vals(optimizer, bench5, space, x0, n_calls)

test_common.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
test_common.py:277: in check_init_vals
    res = optimizer(
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.5       , 0.5710934 ],
       [0.5       , 0.21022448],
       [0.25      , 0.26139364],
       ...,
       [1.        , 0.48720747],
       [0.5       , 0.57206492],
       [1.        , 0.32112269]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=209652396)
y_opt = 1.8963024903367742, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________________________ test_mixed_spaces[optimizer2] ________________________

optimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, n_initial_points=2)

    @pytest.mark.slow_test
    @pytest.mark.parametrize("optimizer", [
            dummy_minimize,
            partial(gp_minimize, n_initial_points=2),
            partial(forest_minimize, n_initial_points=2),
            partial(gbrt_minimize, n_initial_points=2)])
    def test_mixed_spaces(optimizer):
        space = [("-2", "-1", "0", "1", "2"), (-2.0, 2.0)]
        x0 = [["0", 2.0], ["1", 1.0], ["2", 1.0]]
        n_calls = 5
>       check_init_vals(optimizer, bench5, space, x0, n_calls)

test_common.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
test_common.py:277: in check_init_vals
    res = optimizer(
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 0.        ,  0.        ,  0.        ,  1.        ,  0.        ,
         0.28437361],
       [ 0.        ,  1...,
         0.2882597 ],
       [ 0.        ,  0.        ,  0.        ,  0.        ,  1.        ,
        -0.71550924]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=209652396)
y_opt = 1.8963024903367742, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________________________ test_mixed_spaces[optimizer3] ________________________

optimizer = functools.partial(<function gbrt_minimize at 0x000001BCF6A1E200>, n_initial_points=2)

    @pytest.mark.slow_test
    @pytest.mark.parametrize("optimizer", [
            dummy_minimize,
            partial(gp_minimize, n_initial_points=2),
            partial(forest_minimize, n_initial_points=2),
            partial(gbrt_minimize, n_initial_points=2)])
    def test_mixed_spaces(optimizer):
        space = [("-2", "-1", "0", "1", "2"), (-2.0, 2.0)]
        x0 = [["0", 2.0], ["1", 1.0], ["2", 1.0]]
        n_calls = 5
>       check_init_vals(optimizer, bench5, space, x0, n_calls)

test_common.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
test_common.py:277: in check_init_vals
    res = optimizer(
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ,
        -1.95284904],
       [ 0.        ,  0...,
         1.69320227],
       [ 1.        ,  0.        ,  0.        ,  0.        ,  0.        ,
        -0.3750601 ]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCF7BFED40),
                                  random_state=RandomState(MT19937) at 0x1BCF7BFED40)
y_opt = 0.7409034143962148, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________________________ test_repeated_x[gp_minimize] _________________________

minimizer = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.fast_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_repeated_x(minimizer):
        with pytest.warns(None) as record:
>           minimizer(lambda x: x[0], dimensions=[[0, 1]], x0=[[0], [1]],
                      n_initial_points=0, n_calls=3)

test_common.py:353: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:291: in base_minimize
    result = optimizer.tell(x0, y0)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[1.],
       [1.],
       [1.],
       ...,
       [0.],
       [1.],
       [1.]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=1, nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=2107093400)
y_opt = 0, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________________ test_repeated_x[minimizer2] _________________________

minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='ET', acq_func='PI')

    @pytest.mark.fast_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_repeated_x(minimizer):
        with pytest.warns(None) as record:
>           minimizer(lambda x: x[0], dimensions=[[0, 1]], x0=[[0], [1]],
                      n_initial_points=0, n_calls=3)

test_common.py:353: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:291: in base_minimize
    result = optimizer.tell(x0, y0)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[1],
       [0],
       [1],
       ...,
       [0],
       [1],
       [0]], dtype=int64)
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=204954955)
y_opt = 0, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________________ test_repeated_x[minimizer3] _________________________

minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='ET', acq_func='EI')

    @pytest.mark.fast_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_repeated_x(minimizer):
        with pytest.warns(None) as record:
>           minimizer(lambda x: x[0], dimensions=[[0, 1]], x0=[[0], [1]],
                      n_initial_points=0, n_calls=3)

test_common.py:353: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:291: in base_minimize
    result = optimizer.tell(x0, y0)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[1],
       [0],
       [0],
       ...,
       [1],
       [1],
       [0]], dtype=int64)
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=1787361383)
y_opt = 0, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________________ test_repeated_x[minimizer5] _________________________

minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='RF', acq_func='PI')

    @pytest.mark.fast_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_repeated_x(minimizer):
        with pytest.warns(None) as record:
>           minimizer(lambda x: x[0], dimensions=[[0, 1]], x0=[[0], [1]],
                      n_initial_points=0, n_calls=3)

test_common.py:353: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:291: in base_minimize
    result = optimizer.tell(x0, y0)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0],
       [0],
       [0],
       ...,
       [1],
       [0],
       [0]], dtype=int64)
model = RandomForestRegressor(min_samples_leaf=3, n_estimators=100,
                      random_state=1073463058)
y_opt = 0, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________________ test_repeated_x[minimizer6] _________________________

minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='RF', acq_func='EI')

    @pytest.mark.fast_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_repeated_x(minimizer):
        with pytest.warns(None) as record:
>           minimizer(lambda x: x[0], dimensions=[[0, 1]], x0=[[0], [1]],
                      n_initial_points=0, n_calls=3)

test_common.py:353: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:291: in base_minimize
    result = optimizer.tell(x0, y0)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0],
       [1],
       [1],
       ...,
       [0],
       [1],
       [1]], dtype=int64)
model = RandomForestRegressor(min_samples_leaf=3, n_estimators=100,
                      random_state=1179017655)
y_opt = 0, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________________ test_repeated_x[minimizer8] _________________________

minimizer = functools.partial(<function gbrt_minimize at 0x000001BCF6A1E200>, acq_func='PI')

    @pytest.mark.fast_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_repeated_x(minimizer):
        with pytest.warns(None) as record:
>           minimizer(lambda x: x[0], dimensions=[[0, 1]], x0=[[0], [1]],
                      n_initial_points=0, n_calls=3)

test_common.py:353: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:291: in base_minimize
    result = optimizer.tell(x0, y0)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0],
       [1],
       [0],
       ...,
       [0],
       [0],
       [0]], dtype=int64)
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCF7BFE740),
                                  random_state=RandomState(MT19937) at 0x1BCF7BFE740)
y_opt = 0, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________________ test_repeated_x[minimizer9] _________________________

minimizer = functools.partial(<function gbrt_minimize at 0x000001BCF6A1E200>, acq_func='EI')

    @pytest.mark.fast_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_repeated_x(minimizer):
        with pytest.warns(None) as record:
>           minimizer(lambda x: x[0], dimensions=[[0, 1]], x0=[[0], [1]],
                      n_initial_points=0, n_calls=3)

test_common.py:353: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:291: in base_minimize
    result = optimizer.tell(x0, y0)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[1],
       [1],
       [0],
       ...,
       [1],
       [1],
       [1]], dtype=int64)
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCF7BFE040),
                                  random_state=RandomState(MT19937) at 0x1BCF7BFE040)
y_opt = 0, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_______________ test_consistent_x_iter_dimensions[gp_minimize] ________________

minimizer = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.fast_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_consistent_x_iter_dimensions(minimizer):
        # check that all entries in x_iters have the same dimensions
        # two dimensional problem, bench1 is a 1D function but in this
        # instance we do not really care about the objective, could be
        # a total dummy
>       res = minimizer(bench1,
                        dimensions=[(0, 1), (2, 3)],
                        x0=[[0, 2], [1, 2]], n_calls=3,
                        n_initial_points=0)

test_common.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:291: in base_minimize
    result = optimizer.tell(x0, y0)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0., 0.],
       [1., 0.],
       [0., 0.],
       ...,
       [1., 0.],
       [0., 0.],
       [0., 0.]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=23092717)
y_opt = 0, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________________ test_consistent_x_iter_dimensions[minimizer2] ________________

minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='ET', acq_func='PI')

    @pytest.mark.fast_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_consistent_x_iter_dimensions(minimizer):
        # check that all entries in x_iters have the same dimensions
        # two dimensional problem, bench1 is a 1D function but in this
        # instance we do not really care about the objective, could be
        # a total dummy
>       res = minimizer(bench1,
                        dimensions=[(0, 1), (2, 3)],
                        x0=[[0, 2], [1, 2]], n_calls=3,
                        n_initial_points=0)

test_common.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:291: in base_minimize
    result = optimizer.tell(x0, y0)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[1, 3],
       [0, 3],
       [1, 3],
       ...,
       [1, 2],
       [0, 3],
       [1, 3]], dtype=int64)
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=1697407374)
y_opt = 0, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________________ test_consistent_x_iter_dimensions[minimizer3] ________________

minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='ET', acq_func='EI')

    @pytest.mark.fast_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_consistent_x_iter_dimensions(minimizer):
        # check that all entries in x_iters have the same dimensions
        # two dimensional problem, bench1 is a 1D function but in this
        # instance we do not really care about the objective, could be
        # a total dummy
>       res = minimizer(bench1,
                        dimensions=[(0, 1), (2, 3)],
                        x0=[[0, 2], [1, 2]], n_calls=3,
                        n_initial_points=0)

test_common.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:291: in base_minimize
    result = optimizer.tell(x0, y0)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[1, 3],
       [1, 3],
       [1, 2],
       ...,
       [1, 3],
       [0, 3],
       [0, 2]], dtype=int64)
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=1808183834)
y_opt = 0, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________________ test_consistent_x_iter_dimensions[minimizer5] ________________

minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='RF', acq_func='PI')

    @pytest.mark.fast_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_consistent_x_iter_dimensions(minimizer):
        # check that all entries in x_iters have the same dimensions
        # two dimensional problem, bench1 is a 1D function but in this
        # instance we do not really care about the objective, could be
        # a total dummy
>       res = minimizer(bench1,
                        dimensions=[(0, 1), (2, 3)],
                        x0=[[0, 2], [1, 2]], n_calls=3,
                        n_initial_points=0)

test_common.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:291: in base_minimize
    result = optimizer.tell(x0, y0)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0, 3],
       [0, 3],
       [1, 2],
       ...,
       [0, 2],
       [1, 2],
       [1, 2]], dtype=int64)
model = RandomForestRegressor(min_samples_leaf=3, n_estimators=100,
                      random_state=1752674517)
y_opt = 0, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________________ test_consistent_x_iter_dimensions[minimizer6] ________________

minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='RF', acq_func='EI')

    @pytest.mark.fast_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_consistent_x_iter_dimensions(minimizer):
        # check that all entries in x_iters have the same dimensions
        # two dimensional problem, bench1 is a 1D function but in this
        # instance we do not really care about the objective, could be
        # a total dummy
>       res = minimizer(bench1,
                        dimensions=[(0, 1), (2, 3)],
                        x0=[[0, 2], [1, 2]], n_calls=3,
                        n_initial_points=0)

test_common.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:291: in base_minimize
    result = optimizer.tell(x0, y0)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[1, 2],
       [1, 2],
       [1, 3],
       ...,
       [1, 2],
       [1, 2],
       [1, 3]], dtype=int64)
model = RandomForestRegressor(min_samples_leaf=3, n_estimators=100,
                      random_state=1778425390)
y_opt = 0, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________________ test_consistent_x_iter_dimensions[minimizer8] ________________

minimizer = functools.partial(<function gbrt_minimize at 0x000001BCF6A1E200>, acq_func='PI')

    @pytest.mark.fast_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_consistent_x_iter_dimensions(minimizer):
        # check that all entries in x_iters have the same dimensions
        # two dimensional problem, bench1 is a 1D function but in this
        # instance we do not really care about the objective, could be
        # a total dummy
>       res = minimizer(bench1,
                        dimensions=[(0, 1), (2, 3)],
                        x0=[[0, 2], [1, 2]], n_calls=3,
                        n_initial_points=0)

test_common.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:291: in base_minimize
    result = optimizer.tell(x0, y0)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[1, 3],
       [1, 2],
       [1, 3],
       ...,
       [1, 3],
       [0, 2],
       [0, 3]], dtype=int64)
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCF7BFEF40),
                                  random_state=RandomState(MT19937) at 0x1BCF7BFEF40)
y_opt = 0, acq_func = 'PI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________________ test_consistent_x_iter_dimensions[minimizer9] ________________

minimizer = functools.partial(<function gbrt_minimize at 0x000001BCF6A1E200>, acq_func='EI')

    @pytest.mark.fast_test
    @pytest.mark.parametrize("minimizer", MINIMIZERS)
    def test_consistent_x_iter_dimensions(minimizer):
        # check that all entries in x_iters have the same dimensions
        # two dimensional problem, bench1 is a 1D function but in this
        # instance we do not really care about the objective, could be
        # a total dummy
>       res = minimizer(bench1,
                        dimensions=[(0, 1), (2, 3)],
                        x0=[[0, 2], [1, 2]], n_calls=3,
                        n_initial_points=0)

test_common.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:291: in base_minimize
    result = optimizer.tell(x0, y0)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0, 3],
       [1, 2],
       [0, 3],
       ...,
       [1, 3],
       [1, 3],
       [1, 2]], dtype=int64)
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD99040),
                                  random_state=RandomState(MT19937) at 0x1BCFBD99040)
y_opt = 0, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
__________________ test_early_stopping_delta_x[gp_minimize] ___________________

minimizer = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("minimizer",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_early_stopping_delta_x(minimizer):
        n_calls = 11
>       res = minimizer(bench1,
                        callback=DeltaXStopper(0.1),
                        dimensions=[(-1., 1.)],
                        x0=[[-0.1], [0.1], [-0.9]],
                        n_calls=n_calls,
                        n_initial_points=0, random_state=1)

test_common.py:403: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:291: in base_minimize
    result = optimizer.tell(x0, y0)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.99718481],
       [0.93255736],
       [0.12812445],
       ...,
       [0.265739  ],
       [0.07608961],
       [0.76781048]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=1, nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=1791095845)
y_opt = 0.010000000000000002, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________________ test_early_stopping_delta_x[forest_minimize] _________________

minimizer = <function forest_minimize at 0x000001BCF6A0FBA0>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("minimizer",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_early_stopping_delta_x(minimizer):
        n_calls = 11
>       res = minimizer(bench1,
                        callback=DeltaXStopper(0.1),
                        dimensions=[(-1., 1.)],
                        x0=[[-0.1], [0.1], [-0.9]],
                        n_calls=n_calls,
                        n_initial_points=0, random_state=1)

test_common.py:403: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:291: in base_minimize
    result = optimizer.tell(x0, y0)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 0.99436962],
       [ 0.86511472],
       [-0.7437511 ],
       ...,
       [-0.468522  ],
       [-0.84782078],
       [ 0.53562095]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=1791095845)
y_opt = 0.010000000000000002, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_________________ test_early_stopping_delta_x[gbrt_minimize] __________________

minimizer = <function gbrt_minimize at 0x000001BCF6A1E200>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("minimizer",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_early_stopping_delta_x(minimizer):
        n_calls = 11
>       res = minimizer(bench1,
                        callback=DeltaXStopper(0.1),
                        dimensions=[(-1., 1.)],
                        x0=[[-0.1], [0.1], [-0.9]],
                        n_calls=n_calls,
                        n_initial_points=0, random_state=1)

test_common.py:403: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:291: in base_minimize
    result = optimizer.tell(x0, y0)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-0.16595599],
       [ 0.44064899],
       [-0.99977125],
       ...,
       [-0.88093261],
       [-0.78391269],
       [ 0.52558756]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD9BD40),
                                  random_state=RandomState(MT19937) at 0x1BCFBD9BD40)
y_opt = 0.010000000000000002, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________ test_early_stopping_delta_x_empty_result_object[gp_minimize] _________

minimizer = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("minimizer",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_early_stopping_delta_x_empty_result_object(minimizer):
        # check that the callback handles the case of being passed an empty
        # results object, e.g. at the start of the optimization loop
        n_calls = 15
>       res = minimizer(bench1,
                        callback=DeltaXStopper(0.1),
                        dimensions=[(-1., 1.)],
                        n_calls=n_calls,
                        n_initial_points=2, random_state=1)

test_common.py:419: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.12812445],
       [0.99904052],
       [0.23608898],
       ...,
       [0.76781048],
       [0.82511031],
       [0.24662343]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=1, nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=1791095845)
y_opt = 0.7484234764721351, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
______ test_early_stopping_delta_x_empty_result_object[forest_minimize] _______

minimizer = <function forest_minimize at 0x000001BCF6A0FBA0>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("minimizer",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_early_stopping_delta_x_empty_result_object(minimizer):
        # check that the callback handles the case of being passed an empty
        # results object, e.g. at the start of the optimization loop
        n_calls = 15
>       res = minimizer(bench1,
                        callback=DeltaXStopper(0.1),
                        dimensions=[(-1., 1.)],
                        n_calls=n_calls,
                        n_initial_points=2, random_state=1)

test_common.py:419: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-0.7437511 ],
       [ 0.99808103],
       [-0.52782205],
       ...,
       [ 0.53562095],
       [ 0.65022062],
       [-0.50675314]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=1791095845)
y_opt = 0.7484234764721351, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_______ test_early_stopping_delta_x_empty_result_object[gbrt_minimize] ________

minimizer = <function gbrt_minimize at 0x000001BCF6A1E200>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("minimizer",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_early_stopping_delta_x_empty_result_object(minimizer):
        # check that the callback handles the case of being passed an empty
        # results object, e.g. at the start of the optimization loop
        n_calls = 15
>       res = minimizer(bench1,
                        callback=DeltaXStopper(0.1),
                        dimensions=[(-1., 1.)],
                        n_calls=n_calls,
                        n_initial_points=2, random_state=1)

test_common.py:419: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-0.99977125],
       [-0.39533485],
       [-0.70648822],
       ...,
       [ 0.52558756],
       [ 0.53099392],
       [-0.38365446]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCF6AC4D40),
                                  random_state=RandomState(MT19937) at 0x1BCF6AC4D40)
y_opt = 0.02754139081431853, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
____________________ test_per_second_api[gp_minimize-PIps] ____________________

acq_func = 'PIps', minimizer = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.parametrize("acq_func", ACQ_FUNCS_PS)
    @pytest.mark.parametrize("minimizer",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_per_second_api(acq_func, minimizer):
        def bench1_with_time(x):
            return bench1(x), np.abs(x[0])
    
        n_calls = 3
>       res = minimizer(bench1_with_time, [(-2.0, 2.0)],
                        acq_func=acq_func, n_calls=n_calls, n_initial_points=2,
                        random_state=1)

test_common.py:435: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.12812445],
       [0.99904052],
       [0.23608898],
       ...,
       [0.76781048],
       [0.82511031],
       [0.24662343]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=1, nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=1791095845)
y_opt = 0.5482540224644129, acq_func = 'PIps', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
____________________ test_per_second_api[gp_minimize-EIps] ____________________

acq_func = 'EIps', minimizer = <function gp_minimize at 0x000001BCF6A1E160>

    @pytest.mark.parametrize("acq_func", ACQ_FUNCS_PS)
    @pytest.mark.parametrize("minimizer",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_per_second_api(acq_func, minimizer):
        def bench1_with_time(x):
            return bench1(x), np.abs(x[0])
    
        n_calls = 3
>       res = minimizer(bench1_with_time, [(-2.0, 2.0)],
                        acq_func=acq_func, n_calls=n_calls, n_initial_points=2,
                        random_state=1)

test_common.py:435: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.12812445],
       [0.99904052],
       [0.23608898],
       ...,
       [0.76781048],
       [0.82511031],
       [0.24662343]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=1, nu=2.5) + WhiteKernel(noise_level=1),
                         n_restarts_optimizer=2, noise='gaussian',
                         normalize_y=True, random_state=1791095845)
y_opt = 0.5482540224644129, acq_func = 'EIps', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
__________________ test_per_second_api[forest_minimize-PIps] __________________

acq_func = 'PIps', minimizer = <function forest_minimize at 0x000001BCF6A0FBA0>

    @pytest.mark.parametrize("acq_func", ACQ_FUNCS_PS)
    @pytest.mark.parametrize("minimizer",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_per_second_api(acq_func, minimizer):
        def bench1_with_time(x):
            return bench1(x), np.abs(x[0])
    
        n_calls = 3
>       res = minimizer(bench1_with_time, [(-2.0, 2.0)],
                        acq_func=acq_func, n_calls=n_calls, n_initial_points=2,
                        random_state=1)

test_common.py:435: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-1.48750221],
       [ 1.99616206],
       [-1.05564409],
       ...,
       [ 1.07124191],
       [ 1.30044124],
       [-1.01350627]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=1791095845)
y_opt = 0.5482540224644129, acq_func = 'PIps', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
__________________ test_per_second_api[forest_minimize-EIps] __________________

acq_func = 'EIps', minimizer = <function forest_minimize at 0x000001BCF6A0FBA0>

    @pytest.mark.parametrize("acq_func", ACQ_FUNCS_PS)
    @pytest.mark.parametrize("minimizer",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_per_second_api(acq_func, minimizer):
        def bench1_with_time(x):
            return bench1(x), np.abs(x[0])
    
        n_calls = 3
>       res = minimizer(bench1_with_time, [(-2.0, 2.0)],
                        acq_func=acq_func, n_calls=n_calls, n_initial_points=2,
                        random_state=1)

test_common.py:435: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-1.48750221],
       [ 1.99616206],
       [-1.05564409],
       ...,
       [ 1.07124191],
       [ 1.30044124],
       [-1.01350627]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=1791095845)
y_opt = 0.5482540224644129, acq_func = 'EIps', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
___________________ test_per_second_api[gbrt_minimize-PIps] ___________________

acq_func = 'PIps', minimizer = <function gbrt_minimize at 0x000001BCF6A1E200>

    @pytest.mark.parametrize("acq_func", ACQ_FUNCS_PS)
    @pytest.mark.parametrize("minimizer",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_per_second_api(acq_func, minimizer):
        def bench1_with_time(x):
            return bench1(x), np.abs(x[0])
    
        n_calls = 3
>       res = minimizer(bench1_with_time, [(-2.0, 2.0)],
                        acq_func=acq_func, n_calls=n_calls, n_initial_points=2,
                        random_state=1)

test_common.py:435: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-1.9995425 ],
       [-0.79066971],
       [-1.41297644],
       ...,
       [ 1.05117511],
       [ 1.06198784],
       [-0.76730891]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD98040),
                                  random_state=RandomState(MT19937) at 0x1BCFBD98040)
y_opt = -1.1028854621138293, acq_func = 'PIps', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
___________________ test_per_second_api[gbrt_minimize-EIps] ___________________

acq_func = 'EIps', minimizer = <function gbrt_minimize at 0x000001BCF6A1E200>

    @pytest.mark.parametrize("acq_func", ACQ_FUNCS_PS)
    @pytest.mark.parametrize("minimizer",
                             [gp_minimize, forest_minimize, gbrt_minimize])
    def test_per_second_api(acq_func, minimizer):
        def bench1_with_time(x):
            return bench1(x), np.abs(x[0])
    
        n_calls = 3
>       res = minimizer(bench1_with_time, [(-2.0, 2.0)],
                        acq_func=acq_func, n_calls=n_calls, n_initial_points=2,
                        random_state=1)

test_common.py:435: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-1.9995425 ],
       [-0.79066971],
       [-1.41297644],
       ...,
       [ 1.05117511],
       [ 1.06198784],
       [-0.76730891]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCFBD9AE40),
                                  random_state=RandomState(MT19937) at 0x1BCFBD9AE40)
y_opt = -1.1028854621138293, acq_func = 'EIps', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
___________________ test_tree_based_minimize[ET-minimizer0] ___________________

name = 'ET'
minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='ET')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("name, minimizer", MINIMIZERS)
    def test_tree_based_minimize(name, minimizer):
>       check_minimize(minimizer, bench1, 0.05,
                       [(-2.0, 2.0)], 0.05, 25, 5)

test_forest_opt.py:42: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
test_forest_opt.py:33: in check_minimize
    r = minimizer(
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-0.46247317],
       [-0.80986157],
       [-1.77314809],
       ...,
       [ 0.39426184],
       [ 1.76806656],
       [ 0.28437361]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=209652396)
y_opt = 0.1379219701335908, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
___________________ test_tree_based_minimize[RF-minimizer1] ___________________

name = 'RF'
minimizer = functools.partial(<function forest_minimize at 0x000001BCF6A0FBA0>, base_estimator='RF')

    @pytest.mark.slow_test
    @pytest.mark.parametrize("name, minimizer", MINIMIZERS)
    def test_tree_based_minimize(name, minimizer):
>       check_minimize(minimizer, bench1, 0.05,
                       [(-2.0, 2.0)], 0.05, 25, 5)

test_forest_opt.py:42: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
test_forest_opt.py:33: in check_minimize
    r = minimizer(
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-0.46247317],
       [-0.80986157],
       [-1.77314809],
       ...,
       [ 0.39426184],
       [ 1.76806656],
       [ 0.28437361]])
model = RandomForestRegressor(min_samples_leaf=3, n_estimators=100,
                      random_state=209652396)
y_opt = 0.1379219701335908, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
________________ test_tree_based_minimize[gbrt-gbrt_minimize] _________________

name = 'gbrt', minimizer = <function gbrt_minimize at 0x000001BCF6A1E200>

    @pytest.mark.slow_test
    @pytest.mark.parametrize("name, minimizer", MINIMIZERS)
    def test_tree_based_minimize(name, minimizer):
>       check_minimize(minimizer, bench1, 0.05,
                       [(-2.0, 2.0)], 0.05, 25, 5)

test_forest_opt.py:42: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
test_forest_opt.py:33: in check_minimize
    r = minimizer(
..\optimizer\gbrt.py:179: in gbrt_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[ 0.58357645],
       [-0.24965115],
       [ 1.567092  ],
       ...,
       [-0.44390742],
       [-1.84959927],
       [-1.95284904]])
model = GradientBoostingQuantileRegressor(base_estimator=GradientBoostingRegressor(loss='quantile',
                          ...State(MT19937) at 0x1BCF6AC4D40),
                                  random_state=RandomState(MT19937) at 0x1BCF6AC4D40)
y_opt = 0.03223200185492707, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
_______________________ test_tree_based_minimize_n_jobs _______________________

    @pytest.mark.slow_test
    def test_tree_based_minimize_n_jobs():
>       check_minimize(forest_minimize, bench1, 0.05,
                       [(-2.0, 2.0)], 0.05, 25, 5, n_jobs=2)

test_forest_opt.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
test_forest_opt.py:33: in check_minimize
    r = minimizer(
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[-0.46247317],
       [-0.80986157],
       [-1.77314809],
       ...,
       [ 0.39426184],
       [ 1.76806656],
       [ 0.28437361]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100, n_jobs=2,
                    random_state=209652396)
y_opt = 0.1379219701335908, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
__________________________ test_categorical_integer ___________________________

    @pytest.mark.fast_test
    def test_categorical_integer():
        def f(params):
            return 0
    
        dims = [[1]]
>       res = forest_minimize(f, dims, n_calls=1, random_state=1,
                              n_initial_points=1)

test_forest_opt.py:72: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\optimizer\forest.py:186: in forest_minimize
    return base_minimize(func, dimensions, base_estimator,
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0],
       [0],
       [0],
       ...,
       [0],
       [0],
       [0]])
model = ExtraTreesRegressor(min_samples_leaf=3, n_estimators=100,
                    random_state=1791095845)
y_opt = 0, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
____________________ test_gp_minimize_bench1[EI-sampling] _____________________

search = 'sampling', acq = 'EI'

    @pytest.mark.slow_test
    @pytest.mark.parametrize("search", SEARCH)
    @pytest.mark.parametrize("acq", ACQUISITION)
    def test_gp_minimize_bench1(search, acq):
>       check_minimize(bench1, 0.,
                       [(-2.0, 2.0)], search, acq, 0.05, 20)

test_gp_opt.py:34: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
test_gp_opt.py:17: in check_minimize
    r = gp_minimize(func, bounds, acq_optimizer=acq_optimizer,
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.31327352],
       [0.52454816],
       [0.44345289],
       ...,
       [0.97933793],
       [0.67411393],
       [0.05899363]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=1, nu=2.5) + WhiteKernel(noise_level=1e-10),
                         n_restarts_optimizer=2, noise=1e-10, normalize_y=True,
                         random_state=1791095845)
y_opt = 0.17112873546590232, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
______________________ test_gp_minimize_bench1[EI-lbfgs] ______________________

search = 'lbfgs', acq = 'EI'

    @pytest.mark.slow_test
    @pytest.mark.parametrize("search", SEARCH)
    @pytest.mark.parametrize("acq", ACQUISITION)
    def test_gp_minimize_bench1(search, acq):
>       check_minimize(bench1, 0.,
                       [(-2.0, 2.0)], search, acq, 0.05, 20)

test_gp_opt.py:34: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
test_gp_opt.py:17: in check_minimize
    r = gp_minimize(func, bounds, acq_optimizer=acq_optimizer,
..\optimizer\gp.py:259: in gp_minimize
    return base_minimize(
..\optimizer\base.py:300: in base_minimize
    result = optimizer.tell(next_x, next_y)
..\optimizer\optimizer.py:493: in tell
    return self._tell(x, y, fit=fit)
..\optimizer\optimizer.py:557: in _tell
    values = _gaussian_acquisition(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

X = array([[0.31327352],
       [0.52454816],
       [0.44345289],
       ...,
       [0.97933793],
       [0.67411393],
       [0.05899363]])
model = GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=1, nu=2.5) + WhiteKernel(noise_level=1e-10),
                         n_restarts_optimizer=2, noise=1e-10, normalize_y=True,
                         random_state=1791095845)
y_opt = 0.17112873546590232, acq_func = 'EI', return_grad = False
acq_func_kwargs = {'kappa': 1.96, 'xi': 0.01}

    def _gaussian_acquisition(X, model, y_opt=None, acq_func="LCB",
                              return_grad=False, acq_func_kwargs=None):
        """
        Wrapper so that the output of this function can be
        directly passed to a minimizer.
        """
        # Check inputs
        X = np.asarray(X)
        if X.ndim != 2:
            raise ValueError("X is {}-dimensional, however,"
                             " it must be 2-dimensional.".format(X.ndim))
    
        if acq_func_kwargs is None:
            acq_func_kwargs = dict()
        xi = acq_func_kwargs.get("xi", 0.01)
        kappa = acq_func_kwargs.get("kappa", 1.96)
    
        # Evaluate acquisition function
        per_second = acq_func.endswith("ps")
        if per_second:
            model, time_model = model.estimators_
    
        if acq_func == "LCB":
            func_and_grad = gaussian_lcb(X, model, kappa, return_grad)
            if return_grad:
                acq_vals, acq_grad = func_and_grad
            else:
                acq_vals = func_and_grad
    
        elif acq_func in ["EI", "PI", "EIps", "PIps"]:
            if acq_func in ["EI", "EIps"]:
                func_and_grad = gaussian_ei(X, model, y_opt, xi, return_grad)
            else:
                func_and_grad = gaussian_pi(X, model, y_opt, xi, return_grad)
    
            if return_grad:
                acq_vals -= func_and_grad[0]
                acq_grad -= func_and_grad[1]
            else:
>               acq_vals -= func_and_grad
E               UnboundLocalError: cannot access local variable 'acq_vals' where it is not associated with a value

..\acquisition.py:59: UnboundLocalError
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! KeyboardInterrupt !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
C:\bin\venv\.dev311\Lib\site-packages\sklearn\gaussian_process\kernels.py:259: KeyboardInterrupt
(to show a full traceback on KeyboardInterrupt use --full-trace)
=========== 132 failed, 64 passed, 29 warnings in 83.59s (0:01:23) ============
